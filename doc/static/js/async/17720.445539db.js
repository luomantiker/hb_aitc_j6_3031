"use strict";(self.webpackChunkrspress_doc_template=self.webpackChunkrspress_doc_template||[]).push([["17720"],{53584:function(e,n,o){e.exports=o.p+"static/image/input_data_process.b25229e4.png"},62616:function(e,n,o){e.exports=o.p+"static/image/model_optimization.f678a1b6.png"},28784:function(e,n,o){o.r(n);var i=o(85893),s=o(50065),t=o(95895),r=o(53584),l=o(62616);function a(e){let n=Object.assign({h1:"h1",a:"a",p:"p",h2:"h2",code:"code",strong:"strong",ul:"ul",li:"li",div:"div",pre:"pre",span:"span"},(0,s.ah)(),e.components);return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(n.h1,{id:"model-quantization-and-compilation",children:[(0,i.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#model-quantization-and-compilation",children:"#"}),"Model Quantization and Compilation"]}),"\n",(0,i.jsx)(t.Z,{}),"\n",(0,i.jsxs)(n.p,{children:["The conversion of the floating-point model to the Horizonboard-side deployable model will be completed in the Convert Model phase, after which you will get a model that can run on the Horizon computing platform.\nBefore performing the conversion, make sure you have successfully passed the model check as described in the ",(0,i.jsx)(n.a,{href:"/3.0.22/en/guide/ptq/ptq_usage/check_model.html",children:"Check the Model"})," section."]}),"\n",(0,i.jsxs)(n.p,{children:["During the conversion, some important procedures such as model optimization and calibration quantization must prepare the data in line with model pre-processing requirements.\nYou can refer to ",(0,i.jsx)(n.a,{href:"/3.0.22/en/guide/ptq/ptq_usage/prepare_calibration_data.html",children:"Prepare Calibration Data"})," section to prepare the calibration data in advance."]}),"\n",(0,i.jsxs)(n.h2,{id:"convert-the-model-using-the-hb_compile-tool",children:[(0,i.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#convert-the-model-using-the-hb_compile-tool",children:"#"}),"Convert the Model Using the hb_compile Tool"]}),"\n",(0,i.jsxs)(n.p,{children:["The model conversion process is performed using the ",(0,i.jsx)(n.code,{children:"hb_compile"})," tool, please refer to section ",(0,i.jsx)(n.a,{href:"/3.0.22/en/guide/ptq/ptq_tool/hb_compile/convert.html",children:"Model Quantized Compilation"})," for the usage of the tool and the related specific configuration and parameters."]}),"\n",(0,i.jsxs)(n.h2,{id:"conversion_interpretation",children:[(0,i.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#conversion_interpretation",children:"#"}),"Model Conversion Interpretation"]}),"\n",(0,i.jsxs)(n.p,{children:["Model conversion is completed from a floating-point model to a board-side deployable model supported by Horizon's computing platform.\nTo make this model run quickly and efficiently on the embedded end, model conversion focuses mainly on two phases: ",(0,i.jsx)(n.strong,{children:"input data processing"})," and ",(0,i.jsx)(n.strong,{children:"model optimization compilation"}),", and this section will focus on these two problems in turn."]}),"\n",(0,i.jsxs)(n.p,{children:["In terms of ",(0,i.jsx)(n.strong,{children:"Input data processing"}),", Horizon's edge computing platform can provide hardware-level solutions for specific types of input channels, but the output of these solutions may not comply with the input requirements of your models.\nFor example, the video processing sub-systems for video channels have the abilities to crop and scale images or optimize the image quality. The output of these sub-systems are mostly in the YUV420 format, however, the algorithm models are often trained based on commonly-used image formats such as bgr/rgb.\nTo solve this problem, Horizon provides 2 kinds of input descriptions for each converted model: The one is used for the original floating-point model input (",(0,i.jsx)(n.code,{children:"input_type_train"})," and ",(0,i.jsx)(n.code,{children:"input_layout_train"}),"); while the other one is used for the input data ( ",(0,i.jsx)(n.code,{children:"input_type_rt"})," ) of the edge platform that you are going to use."]}),"\n",(0,i.jsxs)(n.p,{children:["For the ",(0,i.jsx)(n.strong,{children:"frequently-used image data pre-processing"}),", such as ",(0,i.jsx)(n.strong,{children:"mean"})," and ",(0,i.jsx)(n.strong,{children:"scale"}),", the edge platform data formats such as yuv420 are no longer suitable for such operations, therefore, we integrate these common image pre-processing into the model.\nAfter the above two processes, the input part of the converted model will be shown as follows"]}),"\n",(0,i.jsx)("img",{src:r}),"\n",(0,i.jsxs)(n.p,{children:["There are only 2 types of data layouts in the above diagram: NCHW and NHWC.\nWherein, N denotes quantity, C denotes channel, H denotes height and W denotes width.\nThe two different layouts reflect different memory access characteristics.\nThe NHWC layout are more often used by the TensorFlow models; while the NCHW layout is used by the Caffe models.\nAlthough Horizon's edge platform doesn't restrict the data layout, there is still a requirement: the ",(0,i.jsx)(n.code,{children:"input_layout_train"})," must be consistent with the data layout of the original floating-point model, as specifying correct data layout is the basis for smooth data parsing."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Model Optimization and Compilation"}),": It includes several important steps, including model parsing, model optimization, model calibration and quantification, and model compilation, and its internal working process is shown in the figure below."]}),"\n",(0,i.jsx)("img",{src:l}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Model Parse Stage"}),": It completes the conversion from Caffe floating-point model to ONNX floating-point model.\nThis stage will name the operator (with a unique name) for the unnamed node/tensor, producing an ",(0,i.jsx)(n.code,{children:"original_float_model.onnx"}),",\nand the computing accuracy of this ONNX model is float32."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Model Optimization Stage"}),": It implements some operator optimization strategies for the model that are applicable to the Horizon platform, such as BN fusion to Conv, etc.\nThe output of this phase is an ",(0,i.jsx)(n.code,{children:"optimized_float_model.onnx"}),". The computational accuracy of this ONNX model is still float32, which will not affect the computational results of the model after optimization."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Model Calibration Stage"}),": It uses the calibration data you provide to calculate the necessary quantization parameters, and the quantization parameters corresponding to each node calculated from the calibration data will be saved in the calibration node.\nThe output of this phase is a ",(0,i.jsx)(n.code,{children:"calibrated_model.onnx"}),". After model calibration, some processing will be performed on the model as well, the output of this process is a ",(0,i.jsx)(n.code,{children:"ptq_model.onnx"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Model Quantization Stage"}),": It uses Horizon's model compiler, which uses the generated model during the model calibration stage(ptq_model.onnx),\nto perform model quantization according to your pre-processing configuration (including the color conversion between input_type_rt to input_type_train, the handling of mean/scale, etc).\nThe output of this phase is a ",(0,i.jsx)(n.code,{children:"quantized_model.bc"}),". The loss of accuracy due to model quantization can be evaluated using this model.\nIf during model quantization there exists a situation of removing nodes at the input/output, a ",(0,i.jsx)(n.code,{children:"quantized_removed_model.bc"})," will also be saved.\nIn this scenario, we recommend you to use this HBIR model to compare with the final generated hbm model if you need to do consistency comparison later."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.div,{className:"rspress-directive warning",children:[(0,i.jsx)(n.div,{className:"rspress-directive-title",children:"Attention"}),(0,i.jsx)(n.div,{className:"rspress-directive-content",children:(0,i.jsxs)(n.p,{children:["Please note that if input_type_rt is nv12, the input layout of ",(0,i.jsx)(n.code,{children:"quantized.bc"})," is NHWC."]})})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Model Compilation Stage"}),": It uses Horizon's model compiler to convert the quantized model computational instructions and data supported by the Horizon platform.\nThe output of this stage is a *.hbm model, this hbm model is the model that will be subsequently run on the Horizon Edge embedded platform, which is the final output result of the model conversion."]}),"\n"]}),"\n",(0,i.jsxs)(n.h1,{id:"interpret-conversion-results",children:[(0,i.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#interpret-conversion-results",children:"#"}),"Interpret Conversion Results"]}),"\n",(0,i.jsxs)(n.p,{children:["This section will introduce the interpretation of successful model conversion status and the analysis of unsuccessful conversions in turn.\nTo confirm the success of the model conversion, you need to check the ",(0,i.jsx)(n.code,{children:"compile"})," status information, the similarity information and the ",(0,i.jsx)(n.code,{children:"working_dir"})," output. For the ",(0,i.jsx)(n.code,{children:"compile"})," status information, after a successful conversion, the model's dependencies and parameters will be output on the console."]}),"\n",(0,i.jsxs)(n.p,{children:["Similarity information will be printed in the console output after ",(0,i.jsx)(n.code,{children:"compile"}),", which takes the following form:"]}),"\n",(0,i.jsx)(n.pre,{className:"code",children:(0,i.jsx)(n.pre,{className:"shiki css-variables has-line-number",style:{backgroundColor:"var(--shiki-color-background)"},tabIndex:"0",children:(0,i.jsxs)(n.code,{className:"language-text",meta:"",children:[(0,i.jsx)(n.span,{className:"line line-number",children:(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"+------------------------------------------+-------------------+-----+-----------+-------------------+------------------+------------------+"})}),"\n",(0,i.jsx)(n.span,{className:"line line-number",children:(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"| Node                                     | NodeType          | ON  | Threshold | Calibrated Cosine | Quantized Cosine | Output Data Type |"})}),"\n",(0,i.jsx)(n.span,{className:"line line-number",children:(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"+------------------------------------------+-------------------+-----+-----------+-------------------+------------------+------------------+"})}),"\n",(0,i.jsx)(n.span,{className:"line line-number",children:(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"| Conv_0+Relu_1                            | Conv+Relu         | BPU | 2.64      | 0.999896          | 0.999315         | si8              |"})}),"\n",(0,i.jsx)(n.span,{className:"line line-number",children:(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"| MaxPool_2                                | MaxPool           | BPU | 2.639386  | 0.999819          | 0.99959          | si8              |"})}),"\n",(0,i.jsx)(n.span,{className:"line line-number",children:(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"| Conv_3+Relu_4                            | Conv+Relu         | BPU | 2.639386  | 0.999697          | 0.999275         | si8              |"})}),"\n",(0,i.jsx)(n.span,{className:"line line-number",children:(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"| Conv_5+Relu_6                            | Conv+Relu         | BPU | 1.139316  | 0.999671          | 0.999462         | si8              |"})}),"\n",(0,i.jsx)(n.span,{className:"line line-number",children:(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"| Conv_7                                   | Conv              | BPU | 1.414045  | 0.999488          | 0.999311         | si8              |"})}),"\n",(0,i.jsx)(n.span,{className:"line line-number",children:(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"..."})}),"\n",(0,i.jsx)(n.span,{className:"line line-number",children:(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"| Conv_114+Relu_115                        | Conv+Relu         | BPU | 1.372878  | 0.994004          | 0.984484         | si8              |"})}),"\n",(0,i.jsx)(n.span,{className:"line line-number",children:(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"| GlobalAveragePool_119                    | GlobalAveragePool | BPU | 11.446251 | 0.997903          | 0.996473         | si8              |"})}),"\n",(0,i.jsx)(n.span,{className:"line line-number",children:(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"| Gemm_121                                 | Conv              | BPU | 6.047658  | 0.998306          | 0.99722          | si32             |"})}),"\n",(0,i.jsx)(n.span,{className:"line line-number",children:(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"| ...121_transpose_output_reshape (output) | Reshape           | BPU | --        | 0.998306          | 0.99722          | si32             |"})}),"\n",(0,i.jsx)(n.span,{className:"line line-number",children:(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"+------------------------------------------+-------------------+-----+-----------+-------------------+------------------+------------------+"})}),"\n",(0,i.jsx)(n.span,{className:"line",children:(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"}})})]})})}),"\n",(0,i.jsx)(n.p,{children:"As shown above:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.strong,{children:"Node"})," and ",(0,i.jsx)(n.strong,{children:"NodeType"})," represents node name and type."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.strong,{children:"ON"})," represents the node executed device, include BPU, CPU and JIT(first generated BPU instructions by the CPU then BPU performs the computation)."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.strong,{children:"Threshold"})," represents to the calibration threshold at each layer, which is used to provide feedback to Horizon technical support in abnormal states and is not of concern in normal conditions."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.strong,{children:"Calibrated Cosine"})," represents the cosine similarity between the outputs of the optimized model (optimized_float_model.onnx) and the calibrated model (calibrated_model.onnx) in the nodes indicated by the ",(0,i.jsx)(n.strong,{children:"Node"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.strong,{children:"Quantized Cosine"})," represents the cosine similarity between the outputs of the optimized model (optimized_float_model.onnx) and the quantized model (quantized_model.bc) generated after model quantization in the nodes indicated by the ",(0,i.jsx)(n.strong,{children:"Node"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.strong,{children:"Output Data type"})," represents the node output data type, range with ['si8', 'si16', 'si32', 'si64', 'ui8', 'ui16', 'ui32', 'ui64', 'f32']."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.div,{className:"rspress-directive warning",children:[(0,i.jsx)(n.div,{className:"rspress-directive-title",children:"Attention"}),(0,i.jsx)(n.div,{className:"rspress-directive-content",children:(0,i.jsxs)(n.p,{children:["Note that the cosine similarity field only serves as a reference to indicate the stability of the quantized data.\nIt cannot directly tell the model accuracy loss. In general, there is a significant loss of accuracy if the similarity of the output nodes is below 0.8.\nOf course, since there is no absolute direct correlation with accuracy, a fully accurate accuracy situation should be described in ",(0,i.jsx)(n.a,{href:"/3.0.22/en/guide/ptq/ptq_usage/accuracy_evaluation.html",children:"Model Accuracy Analysis"})," section."]})})]}),"\n",(0,i.jsxs)(n.p,{children:["The conversion output is stored in the path specified by the conversion configuration parameter ",(0,i.jsx)(n.code,{children:"working_dir"}),".\nYou can get the following files in this directory (* part is what you specify by the conversion configuration parameter ",(0,i.jsx)(n.code,{children:"output_model_file_prefix"}),")."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"*_original_float_model.onnx"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"*_optimized_float_model.onnx"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"*_calibrated_model.onnx"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"*_ptq_model.onnx"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"*_quantized_model.bc"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"*_quantized_removed_model.bc(exist a situation of removing nodes at the input/output)"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"*.hbm"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"*_advice.json"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"*_quant_info.json"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"*_node_info.csv"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"*.html"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"*.json"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.div,{className:"rspress-directive info",children:[(0,i.jsx)(n.div,{className:"rspress-directive-title",children:"Note"}),(0,i.jsx)(n.div,{className:"rspress-directive-content",children:(0,i.jsxs)(n.p,{children:["The * indicates the model file prefix you specify via the ",(0,i.jsx)(n.code,{children:"output_model_file_prefix"})," parameter."]})})]}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.a,{href:"#conversion_output",children:"Interpret Conversion Output"})," section explains the function of each model output.\nHowever, before running on the board, we strongly recommend you to proceed the procedures as described in the sections ",(0,i.jsx)(n.a,{href:"/3.0.22/en/guide/ptq/ptq_usage/performance_evaluation.html",children:"Model Performance Analysis"})," and ",(0,i.jsx)(n.a,{href:"/3.0.22/en/guide/ptq/ptq_usage/accuracy_evaluation.html",children:"Model Accuracy Analysis"})," , to avoid extending the model conversion problem to the subsequent embedded terminal."]}),"\n",(0,i.jsxs)(n.p,{children:["If any of the above-mentioned 3 outputs of verifying the success of the model conversion is missing, there must be something wrong with the conversion.\nIn such cases, the ",(0,i.jsx)(n.code,{children:"compile"})," tool will output error messages to your console in case of errors. For example, if we do not configure the ",(0,i.jsx)(n.code,{children:"prototxt"})," and ",(0,i.jsx)(n.code,{children:"caffe_model"})," parameters during the Caffe model conversion, the tool gives the following message:"]}),"\n",(0,i.jsx)(n.pre,{className:"code",children:(0,i.jsx)(n.pre,{className:"shiki css-variables has-line-number",style:{backgroundColor:"var(--shiki-color-background)"},tabIndex:"0",children:(0,i.jsxs)(n.code,{className:"language-bash",meta:"",children:[(0,i.jsxs)(n.span,{className:"line line-number",children:[(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"2021-04-21"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"14"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:":45:34,085"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"ERROR"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"Key"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string-expression)"},children:"'model_parameters'"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"error:"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "})]}),"\n",(0,i.jsxs)(n.span,{className:"line line-number",children:[(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"Missing"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"keys:"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string-expression)"},children:"'caffe_model'"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:","}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string-expression)"},children:"'prototxt'"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "})]}),"\n",(0,i.jsxs)(n.span,{className:"line line-number",children:[(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"2021-04-21"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"14"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:":45:34,085"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"ERROR"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"yaml"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"file"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"parse"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"failed."}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"Please"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"double"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"check"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"your"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"input"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "})]}),"\n",(0,i.jsxs)(n.span,{className:"line line-number",children:[(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"2021-04-21"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"14"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:":45:34,085"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"ERROR"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"exception"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"in"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"command:"}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,i.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"compile"})]}),"\n"]})})}),"\n",(0,i.jsxs)(n.h2,{id:"conversion_output",children:[(0,i.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#conversion_output",children:"#"}),"Interpret Conversion Output"]}),"\n",(0,i.jsx)(n.p,{children:"The outputs of the successful conversion of the model mentioned above. This section explains the use of each output."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["The output process of *_original_float_model.onnx can be found in ",(0,i.jsx)(n.a,{href:"#conversion_interpretation",children:"Model Conversion Interpretation"}),".\nThe computing accuracy of this model is the same as the original floating-point model.\nIn general, you don't need to use this model. In case of errors in the conversion results, it would be helpful to provide this model to Horizon's technical support to help you solve the problem quickly."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["The output process of *_optimized_float_model.onnx can be found in ",(0,i.jsx)(n.a,{href:"#conversion_interpretation",children:"Model Conversion Interpretation"}),".\nThis model undergoes some operator-level optimization operations, commonly known as operator fusion.\nYou can visually compare it with the original_float model, and clearly find out some operator structural changes, which will not affect the computational accuracy of the model.\nIn general, you do not need to use this model.\nIn case of errors in the conversion results, it would be helpful to provide this model to Horizon's technical support to help you solve the problem quickly."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["The output process of *_calibrated_model.onnx can be found in ",(0,i.jsx)(n.a,{href:"#conversion_interpretation",children:"Model Conversion Interpretation"}),".\nThis model is an intermediate product obtained by the model transformation tool chain by taking the floating-point model after structural optimization, calculating the quantization parameters corresponding to each node from the calibration data and saving them in the calibration node."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["The output process of *_ptq_model.onnx can be found in ",(0,i.jsx)(n.a,{href:"#conversion_interpretation",children:"Model Conversion Interpretation"}),".\nThis model is the product of pre-quantization of the model obtained from calibration by the model conversion toolchain."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["The output process of the *_quantized_model.bc can be found in ",(0,i.jsx)(n.a,{href:"#conversion_interpretation",children:"Model Conversion Interpretation"}),".\nThis model has completed the calibration and quantization process, and the quantized accuracy loss can be viewed here.\nThis model is a mandatory model in the accuracy verification process, please refer to the introduction of ",(0,i.jsx)(n.a,{href:"/3.0.22/en/guide/ptq/ptq_usage/accuracy_evaluation.html",children:"Model Accuracy Analysis"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["The output process of the *_quantized_removed_model.bc can be found in ",(0,i.jsx)(n.a,{href:"#conversion_interpretation",children:"Model Conversion Interpretation"}),".\nIf during model quantization there exists a situation of removing nodes at the input/output, this removed node's HBIR model will be automatically saved.\nIn this scenario, we recommend you to use this HBIR model to compare with the final generated hbm model if you need to do consistency comparison later."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["The *.hbm is the model that can be used to load and run on the Horizon computing platform. After reading ",(0,i.jsx)(n.a,{href:"/3.0.22/en/guide/ucp/runtime/runtime_dev.html",children:"Embedded Application Development"}),".\nYou can then deploy the model to run on the computing platform quickly.\nHowever, to ensure that the performance and accuracy of the model is as good as you expect, we strongly recommend completing the ",(0,i.jsx)(n.a,{href:"/3.0.22/en/guide/ptq/ptq_usage/performance_evaluation.html",children:"Model Performance Analysis"})," and ",(0,i.jsx)(n.a,{href:"/3.0.22/en/guide/ptq/ptq_usage/accuracy_evaluation.html",children:"Model Accuracy Analysis"})," , before moving on to application development and development."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"The *_advice.json file contains the results printed by the Horizon Model Compiler op checker."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"The *_quant_info.json file contains the calibrated quantization information of the operators."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"The *_node_info.csv file contains the result of the cosine similarity and other information of the operator after successful conversion, which is the same as the similarity information output in the console after successful execution of hb_compile."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"The *.json is the model static performance evaluation file."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"The *.html is the model static performance evaluation file (better readability)."}),"\n"]}),"\n"]})]})}function c(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:n}=Object.assign({},(0,s.ah)(),e.components);return n?(0,i.jsx)(n,Object.assign({},e,{children:(0,i.jsx)(a,e)})):a(e)}n.default=c,c.__RSPRESS_PAGE_META={},c.__RSPRESS_PAGE_META["3.0.22%2Fen%2Fguide%2Fptq%2Fptq_usage%2Fquantize_compile.mdx"]={toc:[{id:"convert-the-model-using-the-hb_compile-tool",text:"Convert the Model Using the hb_compile Tool",depth:2},{id:"conversion_interpretation",text:"Model Conversion Interpretation",depth:2},{id:"conversion_output",text:"Interpret Conversion Output",depth:2}],title:"Model Quantization and Compilation",frontmatter:{}}},95895:function(e,n,o){o(39710);var i=o(85893),s=o(67294),t=o(45687);o(20388);let r={"zh-CN":e=>`\u{9884}\u{8BA1}\u{9605}\u{8BFB}\u{65F6}\u{95F4}: ${e.minutes>=1?`${Math.ceil(e.minutes)} \u{5206}\u{949F}`:"\u5C0F\u4E8E 1 \u5206\u949F"}`,"en-US":e=>`Estimated reading time: ${e.minutes>=1?`${Math.ceil(e.minutes)} minutes`:"less than 1 minute"}`};function l(e,n,o){let i=Object.keys(r).includes(n)?n:o;return r[i](e)}n.Z=e=>{let{defaultLocale:n="en-US"}=e,o=(0,t.Vi)().page.readingTimeData,r=(0,t.Jr)(),a=(0,t.e7)(),[c,d]=(0,s.useState)(l(o,r,n));return(0,s.useEffect)(()=>{d(l(o,r,n))},[r,o]),(0,i.jsx)("span",{"data-dark":String(a),className:"rp-reading-time",children:c})}}}]);