"use strict";(self.webpackChunkrspress_doc_template=self.webpackChunkrspress_doc_template||[]).push([["58508"],{5052:function(e,n,i){e.exports=i.p+"static/image/pipeline.993741f8.png"},88371:function(e,n,i){i.r(n);var t=i(85893),s=i(50065),r=i(95895),o=i(5052);function a(e){let n=Object.assign({h1:"h1",a:"a",h2:"h2",p:"p",strong:"strong",ul:"ul",li:"li",code:"code"},(0,s.ah)(),e.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.h1,{id:"framework",children:[(0,t.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#framework",children:"#"}),"Framework"]}),"\n",(0,t.jsx)(r.Z,{}),"\n",(0,t.jsxs)(n.h2,{id:"core-modules",children:[(0,t.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#core-modules",children:"#"}),"Core Modules"]}),"\n",(0,t.jsx)("img",{src:o,alt:"Abstract Flow Chart",width:"850"}),"\n",(0,t.jsxs)(n.p,{children:["The above figure shows the abstract flowchart of the overall organization of the HAT framework. You can see that the training and verification process of HAT is composed of four core modules, namely ",(0,t.jsx)(n.strong,{children:"Data"}),", ",(0,t.jsx)(n.strong,{children:"Model"}),", ",(0,t.jsx)(n.strong,{children:"Callback"}),", and ",(0,t.jsx)(n.strong,{children:"Engine"}),". Here is a brief introduction to each of these core modules."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Data: Responsible for all the data producing processes in HAT, including ",(0,t.jsx)(n.code,{children:"Dataset"})," (iterative output), ",(0,t.jsx)(n.code,{children:"Transforms"})," (data enhancement for tasks), ",(0,t.jsx)(n.code,{children:"Collate"})," (data concatenation and batch packing), and ",(0,t.jsx)(n.code,{children:"Sampler"})," (data sampling process). All the data producing processes are finally organized in a unified way through the ",(0,t.jsx)(n.code,{children:"Dataloader"})," interface."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Model: Responsible for the building process of all the models in HAT. In HAT, the model is generally divided into sub-modules such as ",(0,t.jsx)(n.code,{children:"backbone"}),", ",(0,t.jsx)(n.code,{children:"neck"}),", ",(0,t.jsx)(n.code,{children:"head"}),", ",(0,t.jsx)(n.code,{children:"task module"}),", etc., and a unified ",(0,t.jsx)(n.code,{children:"structure"})," is used to link all the sub-modules to build the final model. Besides the common tasks,  ",(0,t.jsx)(n.code,{children:"structure"})," also uses a ",(0,t.jsx)(n.code,{children:"GraphModel"})," to specially handle the multitasking related model structure building."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Callback: Responsible for dynamically adjusting the training state during the execution of the Engine. Similar to the ",(0,t.jsx)(n.code,{children:"Hooks"})," of the model in ",(0,t.jsx)(n.code,{children:"Torch"}),", it can perform dynamic adjustments in the specified modifiable positions according to the training state provided by ",(0,t.jsx)(n.code,{children:"Engine"})," without modifying the ",(0,t.jsx)(n.code,{children:"Engine"})," code. The modifiable positions of the whole ",(0,t.jsx)(n.code,{children:"Engine"})," mainly include: ",(0,t.jsx)(n.code,{children:"on_loop_begin(end)"}),", ",(0,t.jsx)(n.code,{children:"on_epoch_begin(end)"}),", ",(0,t.jsx)(n.code,{children:"on_step_begin(end)"}),", and ",(0,t.jsx)(n.code,{children:"on_batch_begin(end)"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Engine: Mainly responsible for building and executing the training or prediction process, including the training module ",(0,t.jsx)(n.code,{children:"Trainer"})," and the prediction module ",(0,t.jsx)(n.code,{children:"Precitor"}),". All other modules, such as ",(0,t.jsx)(n.code,{children:"Data"}),", ",(0,t.jsx)(n.code,{children:"Model"}),", ",(0,t.jsx)(n.code,{children:"Callback"}),", etc., will be fed to ",(0,t.jsx)(n.code,{children:"Engine"})," after building, and ",(0,t.jsx)(n.code,{children:"Engine"})," will implement unified scheduling to complete the whole process of the training or prediction."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["In addition to the four core modules, there are other supporting modules such as ",(0,t.jsx)(n.strong,{children:"Profiler"}),", ",(0,t.jsx)(n.strong,{children:"Metric"}),", ",(0,t.jsx)(n.strong,{children:"Visualize"}),", etc."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Profiler: As the ",(0,t.jsx)(n.code,{children:"prof"})," tool of HAT, it mainly helps to locate the speed bottleneck during the training or validation."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Metric: Mainly used for metrics validation during dataset training or testing, which is actually a special case of ",(0,t.jsx)(n.code,{children:"Model"})," and strongly bound to specific datasets."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Visualize: Mainly used for the visualization of relevant datasets."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.h2,{id:"training-building-process",children:[(0,t.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#training-building-process",children:"#"}),"Training Building Process"]}),"\n",(0,t.jsxs)(n.p,{children:["1.For any dataset, build all the submodules required by ",(0,t.jsx)(n.code,{children:"Data"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["First build ",(0,t.jsx)(n.code,{children:"Dataset"})," for iterative output, and process the data with ",(0,t.jsx)(n.code,{children:"Transform"})," in the iterative output, e.g., data enhancement operations in training, data preprocessing in testing, etc. Then use ",(0,t.jsx)(n.code,{children:"Sampler"})," to control the output order of ",(0,t.jsx)(n.code,{children:"Dataset"}),", and use ",(0,t.jsx)(n.code,{children:"Collate"})," to concatenate the data one by one, and finally pack a ",(0,t.jsx)(n.code,{children:"Batch"})," of training data. The ",(0,t.jsx)(n.code,{children:"DataLoader"})," unifies the scheduling of all processes and feeds the training data of the ",(0,t.jsx)(n.code,{children:"Batch"})," into the training process as structures."]}),"\n",(0,t.jsxs)(n.p,{children:["2.For any model, build all the submodules required by ",(0,t.jsx)(n.code,{children:"Model"}),", e.g., ",(0,t.jsx)(n.code,{children:"Backbone"}),", ",(0,t.jsx)(n.code,{children:"Neck"}),", etc."]}),"\n",(0,t.jsxs)(n.p,{children:["Use ",(0,t.jsx)(n.code,{children:"Structure"})," to link all the sub-modules together to form a complete model with training states, which will also be fed to the training process as a training object."]}),"\n",(0,t.jsxs)(n.p,{children:["3.For the training task, select or define a suitable ",(0,t.jsx)(n.code,{children:"Callback"})," to dynamically adjust the training state during the training."]}),"\n",(0,t.jsxs)(n.p,{children:["For example, in each training session, output training results at regular intervals or dynamically adjust the learning rate of the training. Although the definition of ",(0,t.jsx)(n.code,{children:"Callback"})," and ",(0,t.jsx)(n.code,{children:"Engine"})," are separate, the execution process is embedded in the complete process of ",(0,t.jsx)(n.code,{children:"Engine"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["4.For the training environment, build a suitable ",(0,t.jsx)(n.code,{children:"Engine"})," as the training engine."]}),"\n",(0,t.jsxs)(n.p,{children:["For example, you can choose ",(0,t.jsx)(n.code,{children:"DistributedDataParallelTrainer"})," or ",(0,t.jsx)(n.code,{children:"DataParallelTrainer"})," for common multi-card training environments. The ",(0,t.jsx)(n.code,{children:"Engine"})," can organize all the already-built modules together to complete all the environmental initialization needed by the training, including ",(0,t.jsx)(n.code,{children:"Data"}),", ",(0,t.jsx)(n.code,{children:"Model"}),", or other modules such as ",(0,t.jsx)(n.code,{children:"Callback"}),", ",(0,t.jsx)(n.code,{children:"Metric"}),", ",(0,t.jsx)(n.code,{children:"Profiler"}),". Note that not all the modules in ",(0,t.jsx)(n.code,{children:"Engine"})," are required."]}),"\n",(0,t.jsxs)(n.p,{children:["5.Finally, uniformly use the selected ",(0,t.jsx)(n.code,{children:"fit"})," interface in ",(0,t.jsx)(n.code,{children:"Engine"})," to complete the whole training process."]}),"\n",(0,t.jsxs)(n.p,{children:["The above is the overall structure of the HAT framework and the abstract flow of the training. The diagram at the beginning of this section not only reflects the data flow of the construction, but also includes invocation relationships between modules. For training, ",(0,t.jsx)(n.code,{children:"Engine"})," is the core part. A comprehensive understanding of the operation flow of ",(0,t.jsx)(n.code,{children:"Engine"})," will allow us to understand the entire data flow of HAT."]})]})}function d(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:n}=Object.assign({},(0,s.ah)(),e.components);return n?(0,t.jsx)(n,Object.assign({},e,{children:(0,t.jsx)(a,e)})):a(e)}n.default=d,d.__RSPRESS_PAGE_META={},d.__RSPRESS_PAGE_META["3.0.22%2Fen%2Fguide%2Fadvanced_content%2Fhat%2Fframework%2Fframework.mdx"]={toc:[{id:"core-modules",text:"Core Modules",depth:2},{id:"training-building-process",text:"Training Building Process",depth:2}],title:"Framework",frontmatter:{}}},95895:function(e,n,i){i(39710);var t=i(85893),s=i(67294),r=i(45687);i(20388);let o={"zh-CN":e=>`\u{9884}\u{8BA1}\u{9605}\u{8BFB}\u{65F6}\u{95F4}: ${e.minutes>=1?`${Math.ceil(e.minutes)} \u{5206}\u{949F}`:"\u5C0F\u4E8E 1 \u5206\u949F"}`,"en-US":e=>`Estimated reading time: ${e.minutes>=1?`${Math.ceil(e.minutes)} minutes`:"less than 1 minute"}`};function a(e,n,i){let t=Object.keys(o).includes(n)?n:i;return o[t](e)}n.Z=e=>{let{defaultLocale:n="en-US"}=e,i=(0,r.Vi)().page.readingTimeData,o=(0,r.Jr)(),d=(0,r.e7)(),[l,c]=(0,s.useState)(a(i,o,n));return(0,s.useEffect)(()=>{c(a(i,o,n))},[o,i]),(0,t.jsx)("span",{"data-dark":String(d),className:"rp-reading-time",children:l})}}}]);