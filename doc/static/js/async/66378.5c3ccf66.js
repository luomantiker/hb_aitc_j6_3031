"use strict";(self.webpackChunkrspress_doc_template=self.webpackChunkrspress_doc_template||[]).push([["66378"],{66244:function(e,t,r){r.r(t);var n=r(85893),o=r(50065),i=r(95895);function a(e){let t=Object.assign({h1:"h1",a:"a",h2:"h2",p:"p",code:"code",ul:"ul",li:"li",hr:"hr",ol:"ol",strong:"strong"},(0,o.ah)(),e.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(t.h1,{id:"common-failure",children:[(0,n.jsx)(t.a,{className:"header-anchor","aria-hidden":"true",href:"#common-failure",children:"#"}),"Common Failure"]}),"\n",(0,n.jsx)(i.Z,{}),"\n",(0,n.jsxs)(t.h2,{id:"import-error",children:[(0,n.jsx)(t.a,{className:"header-anchor","aria-hidden":"true",href:"#import-error",children:"#"}),"import Error"]}),"\n",(0,n.jsxs)(t.p,{children:["Error I: ",(0,n.jsx)(t.code,{children:"Cannot find the extension library(_C.so)"})]}),"\n",(0,n.jsx)(t.p,{children:"Solution:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Make sure that the horizon_plugin_pytorch version corresponds to the cuda version."}),"\n",(0,n.jsx)(t.li,{children:"In python3, find the execution path of horizon_plugin_pytorch and check for .so files in that directory. There may be multiple versions of horizon_plugin_pytorch at the same time, so you need to uninstall it and keep only the one you need."}),"\n"]}),"\n",(0,n.jsx)(t.hr,{}),"\n",(0,n.jsxs)(t.p,{children:["Error II: ",(0,n.jsx)(t.code,{children:"RuntimeError: Cannot load custom ops. Please rebuild the horizon_plugin_pytorch"})]}),"\n",(0,n.jsx)(t.p,{children:"Solution: check if the local CUDA environment is OK, such as path, version, etc."}),"\n",(0,n.jsxs)(t.h2,{id:"unable-to-prepare_calibrationqat",children:[(0,n.jsx)(t.a,{className:"header-anchor","aria-hidden":"true",href:"#unable-to-prepare_calibrationqat",children:"#"}),"Unable to prepare_calibration/qat"]}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.code,{children:"RuntimeError: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment"})}),"\n",(0,n.jsx)(t.p,{children:"Solution: generally it is the inclusion of a non-leaf tensor in the model that causes this error, try the following:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Set the inplace of prepare_calibration/qat to True."}),"\n",(0,n.jsx)(t.li,{children:"This error does not occur with normal horizon_plugin_pytorch definitions operators, check if there is a non-leaf tensor defined for the customized operator in the model."}),"\n"]}),"\n",(0,n.jsxs)(t.h2,{id:"forward-error-after-prepare_qat",children:[(0,n.jsx)(t.a,{className:"header-anchor","aria-hidden":"true",href:"#forward-error-after-prepare_qat",children:"#"}),"forward Error after prepare_qat"]}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.code,{children:"TypeError: when calling function <built-in method conv2d of type object at >"})}),"\n",(0,n.jsx)(t.p,{children:"Solution: the customized operator inherits the Module operator of a torch, which results in prepare_qat not being converted to a qat module. it is recommended to use the submodule method to call conv2d."}),"\n",(0,n.jsxs)(t.h2,{id:"quantized-accuracy-anomaly",children:[(0,n.jsx)(t.a,{className:"header-anchor","aria-hidden":"true",href:"#quantized-accuracy-anomaly",children:"#"}),"Quantized Accuracy Anomaly"]}),"\n",(0,n.jsx)(t.p,{children:"The QAT/Quantized accuracy is not as expected, there is a NAN, or the initial QAT loss is clearly anomalous with respect to float."}),"\n",(0,n.jsxs)(t.p,{children:["Solution: please refer to the section ",(0,n.jsx)(t.a,{href:"/3.0.22/en/guide/plugin/user_guide/quant_analysis.html",children:"Accuracy Tuning Tool Guide"}),"."]}),"\n",(0,n.jsxs)(t.h2,{id:"cannot-find-the-extension-library_cso",children:[(0,n.jsx)(t.a,{className:"header-anchor","aria-hidden":"true",href:"#cannot-find-the-extension-library_cso",children:"#"}),"Cannot find the extension library(_C.so)"]}),"\n",(0,n.jsx)(t.p,{children:"Solution: it mainly happens when horizon_plugin_pytorch installs successfully but import fails, the solution is as follows:"}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsx)(t.li,{children:"Make sure that the horizon_plugin_pytorch version and the cuda version correspond;"}),"\n",(0,n.jsx)(t.li,{children:"In python3, find the execution path of horizon-plugin-pytorch and check for .so files in that directory. There may be multiple versions of horizon-plugin-pytorch at the same time, so you need to uninstall it and keep only the one you need."}),"\n"]}),"\n",(0,n.jsxs)(t.h2,{id:"runtimeerror-cannot-load-custom-ops-please-rebuild-the-horizon_plugin_pytorch",children:[(0,n.jsx)(t.a,{className:"header-anchor","aria-hidden":"true",href:"#runtimeerror-cannot-load-custom-ops-please-rebuild-the-horizon_plugin_pytorch",children:"#"}),"RuntimeError: Cannot load custom ops. Please rebuild the horizon_plugin_pytorch."]}),"\n",(0,n.jsx)(t.p,{children:"Solution: please make sure that the local CUDA environment is working properly, e.g., the path and version are as expected."}),"\n",(0,n.jsxs)(t.h2,{id:"runtimeerror-only-tensors-created-explicitly-by-the-user-graph-leaves-support-the-deepcopy-protocol-at-the-moment",children:[(0,n.jsx)(t.a,{className:"header-anchor","aria-hidden":"true",href:"#runtimeerror-only-tensors-created-explicitly-by-the-user-graph-leaves-support-the-deepcopy-protocol-at-the-moment",children:"#"}),"RuntimeError: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment"]}),"\n",(0,n.jsx)(t.p,{children:"Solution: it mainly occurs in the phase of not being able to prepare properly, which is usually caused by non-leaf tensor in the model, please configure the inplace of prepare_calibration/qat to True."}),"\n",(0,n.jsxs)(t.h2,{id:"torchmultiprocessingspawnprocessexitedexception-process-0-terminated-with-signal-sigkill",children:[(0,n.jsx)(t.a,{className:"header-anchor","aria-hidden":"true",href:"#torchmultiprocessingspawnprocessexitedexception-process-0-terminated-with-signal-sigkill",children:"#"}),"torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGKILL"]}),"\n",(0,n.jsx)(t.p,{children:"Solution: probably caused by a multi-threaded, python program that wasn't completely killed."}),"\n",(0,n.jsxs)(t.h2,{id:"attributeerror-nonetype-object-has-no-attribute-numel",children:[(0,n.jsx)(t.a,{className:"header-anchor","aria-hidden":"true",href:"#attributeerror-nonetype-object-has-no-attribute-numel",children:"#"}),"AttributeError: 'NoneType' object has no attribute 'numel'"]}),"\n",(0,n.jsx)(t.p,{children:"Solution: this error occurs mainly during the insertion of pseudo-quantized nodes and is caused by the input scale of the operator being None. The reason may be that the output layer conv is inserted into dequant and then connected to an op, which is similar to the structure of conv+dequant+conv; or the conv configured with high accuracy output is connected to other operators. In this case, please check whether the dequant operator or the high accuracy output configuration is used correctly."}),"\n",(0,n.jsxs)(t.h2,{id:"symbolically-traced-variables-cannot-be-used-as-inputs-to-control-flow",children:[(0,n.jsx)(t.a,{className:"header-anchor","aria-hidden":"true",href:"#symbolically-traced-variables-cannot-be-used-as-inputs-to-control-flow",children:"#"}),"symbolically traced variables cannot be used as inputs to control flow"]}),"\n",(0,n.jsx)(t.p,{children:"Solution: this error is caused by using dynamic control flow such as if, loop, etc. in fx mode. Currently, fx mode only supports static control flow, so you need to avoid using dynamic statements such as if, for, assert, etc. in forward."}),"\n",(0,n.jsxs)(t.h2,{id:"notimplementederror-function-method-neg-of-torch_c_tensorbase-objects-is-not-implemented-for-qtensor",children:[(0,n.jsx)(t.a,{className:"header-anchor","aria-hidden":"true",href:"#notimplementederror-function-method-neg-of-torch_c_tensorbase-objects-is-not-implemented-for-qtensor",children:"#"}),"NotImplementedError: function <method \u2018neg\u2019 of \u2018torch._C._TensorBase\u2019 objects> is not implemented for QTensor."]}),"\n",(0,n.jsx)(t.p,{children:"Solution: this error may occur in the Calibration phase in fx mode because fx mode does not support calculations of the form (-x), please change (-x) to (-1)*(x)."}),"\n",(0,n.jsxs)(t.h2,{id:"notimplementederror-function-function-tensorrsub-at-0x7f5a7cdiee50-is-not-implemented-for-qtensor",children:[(0,n.jsx)(t.a,{className:"header-anchor","aria-hidden":"true",href:"#notimplementederror-function-function-tensorrsub-at-0x7f5a7cdiee50-is-not-implemented-for-qtensor",children:"#"}),"NotimplementedError: function <function Tensor.",(0,n.jsx)(t.strong,{children:"rsub"})," at 0x7f5a7cdiee50> is not implemented for QTensor."]}),"\n",(0,n.jsx)(t.p,{children:"Solution: this error may occur in the Calibration phase in fx mode because the logic of operator substitution in fx mode is that if the subtracted number in the subtraction is a constant, the operator substitution is not performed automatically, so you need to change the subtraction to addition, e.g., change (1-x) to (x+(-1))*(-1)."})]})}function s(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:t}=Object.assign({},(0,o.ah)(),e.components);return t?(0,n.jsx)(t,Object.assign({},e,{children:(0,n.jsx)(a,e)})):a(e)}t.default=s,s.__RSPRESS_PAGE_META={},s.__RSPRESS_PAGE_META["3.0.22%2Fen%2Fguide%2Fplugin%2Fqat_faq%2Ffailure.mdx"]={toc:[{id:"import-error",text:"import Error",depth:2},{id:"unable-to-prepare_calibrationqat",text:"Unable to prepare_calibration/qat",depth:2},{id:"forward-error-after-prepare_qat",text:"forward Error after prepare_qat",depth:2},{id:"quantized-accuracy-anomaly",text:"Quantized Accuracy Anomaly",depth:2},{id:"cannot-find-the-extension-library_cso",text:"Cannot find the extension library(_C.so)",depth:2},{id:"runtimeerror-cannot-load-custom-ops-please-rebuild-the-horizon_plugin_pytorch",text:"RuntimeError: Cannot load custom ops. Please rebuild the horizon_plugin_pytorch.",depth:2},{id:"runtimeerror-only-tensors-created-explicitly-by-the-user-graph-leaves-support-the-deepcopy-protocol-at-the-moment",text:"RuntimeError: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment",depth:2},{id:"torchmultiprocessingspawnprocessexitedexception-process-0-terminated-with-signal-sigkill",text:"torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGKILL",depth:2},{id:"attributeerror-nonetype-object-has-no-attribute-numel",text:"AttributeError: 'NoneType' object has no attribute 'numel'",depth:2},{id:"symbolically-traced-variables-cannot-be-used-as-inputs-to-control-flow",text:"symbolically traced variables cannot be used as inputs to control flow",depth:2},{id:"notimplementederror-function-method-neg-of-torch_c_tensorbase-objects-is-not-implemented-for-qtensor",text:"NotImplementedError: function <method \u2018neg\u2019 of \u2018torch._C._TensorBase\u2019 objects> is not implemented for QTensor.",depth:2},{id:"notimplementederror-function-function-tensorrsub-at-0x7f5a7cdiee50-is-not-implemented-for-qtensor",text:"NotimplementedError: function <function Tensor.**rsub** at 0x7f5a7cdiee50> is not implemented for QTensor.",depth:2}],title:"Common Failure",frontmatter:{}}},95895:function(e,t,r){r(39710);var n=r(85893),o=r(67294),i=r(45687);r(20388);let a={"zh-CN":e=>`\u{9884}\u{8BA1}\u{9605}\u{8BFB}\u{65F6}\u{95F4}: ${e.minutes>=1?`${Math.ceil(e.minutes)} \u{5206}\u{949F}`:"\u5C0F\u4E8E 1 \u5206\u949F"}`,"en-US":e=>`Estimated reading time: ${e.minutes>=1?`${Math.ceil(e.minutes)} minutes`:"less than 1 minute"}`};function s(e,t,r){let n=Object.keys(a).includes(t)?t:r;return a[n](e)}t.Z=e=>{let{defaultLocale:t="en-US"}=e,r=(0,i.Vi)().page.readingTimeData,a=(0,i.Jr)(),c=(0,i.e7)(),[l,h]=(0,o.useState)(s(r,a,t));return(0,o.useEffect)(()=>{h(s(r,a,t))},[a,r]),(0,n.jsx)("span",{"data-dark":String(c),className:"rp-reading-time",children:l})}}}]);