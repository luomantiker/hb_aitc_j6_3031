"use strict";(self.webpackChunkrspress_doc_template=self.webpackChunkrspress_doc_template||[]).push([["97019"],{28259:function(e,n,i){e.exports=i.p+"static/image/slam.06a1fa94.png"},84310:function(e,n,i){i.r(n);var t=i(85893),a=i(50065),o=i(95895),r=i(28259);function s(e){let n=Object.assign({h1:"h1",a:"a",p:"p",h2:"h2"},(0,a.ah)(),e.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.h1,{id:"slam-example-introduction",children:[(0,t.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#slam-example-introduction",children:"#"}),"SLAM Example Introduction"]}),"\n",(0,t.jsx)(o.Z,{}),"\n",(0,t.jsx)(n.p,{children:"The DSP example package is developed based on the SLAM example package provided by Cadence and can be run on a board or in simulation. This chapter will briefly introduce the SLAM DSP example process."}),"\n",(0,t.jsxs)(n.h2,{id:"principle-introduction",children:[(0,t.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#principle-introduction",children:"#"}),"Principle Introduction"]}),"\n",(0,t.jsx)(n.p,{children:"SLAM(simultaneous localization and mapping), also known as CML(Concurrent Mapping and Localization), is a concept used to locate in an environment and describe the current environment for route planning; it records information obtained by some form of perception and compares it with the current perception results to support the evaluation of actual positioning. The problem can be described as: if a robot is placed in an unknown position in an unknown environment, is there a way for the robot to gradually draw a complete map of the environment while deciding in which direction the robot should go."}),"\n",(0,t.jsxs)(n.h2,{id:"slam-implementation-process",children:[(0,t.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#slam-implementation-process",children:"#"}),"SLAM Implementation Process"]}),"\n",(0,t.jsxs)(n.p,{children:["The visual SLAM application example is based on the open source ",(0,t.jsx)(n.a,{href:"https://github.com/raulmur/ORB_SLAM2",target:"_blank",rel:"noopener noreferrer",children:"ORB_SLAM2"})," implementation. However, the application only extracts the most basic functions and simplifies and modifies them in various functions. These modifications are designed to adapt to the SIMD implementation on the Vision DSP to improve loop performance and reduce frequent random accesses to system memory. In addition, additional functions for removing outliers have been added in various modules."]}),"\n",(0,t.jsx)(n.p,{children:'The SLAM application also supports "binocular stereo" and "RGBD" inputs. However, its approach is significantly different from that of ORB_SLAM2. ORB_SLAM2 uses additional information (right image in binocular stereo vision and depth information in RGBD) to reduce reprojection error or cost function. Instead, the application uses a proprietary method that leverages this additional information to perform outlier rejection.'}),"\n",(0,t.jsx)(n.p,{children:"The figure below shows the module diagram of the SLAM application. The SLAM application can accept monocular, binocular stereo or RGBD input. In case of RGBD input, grayscale monocular image and depth image are provided as input. Keypoints or corner points are then detected from the input image and descriptors are created for these keypoints, which are used for matching. In the case of binocular stereo input, depth information is generated from binocular stereo images. For monocular input, in the initial state, the SLAM application tries to find a set of two keyframes to obtain the initial 3D point set and pose. For RGBD and stereo input, 3D points are generated on the first frame and the application is initialized. Once the application is initialized, it enters the tracking state, estimating the camera pose through pose optimization in each frame using known 3D points and their observed projections. Depending on the conditions, keyframes (KFs) are inserted to generate new 3D point sets, and local bundle adjustments further optimize the estimated 3D points and poses."}),"\n",(0,t.jsx)("img",{src:r,alt:"slam block",width:"900"})]})}function c(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:n}=Object.assign({},(0,a.ah)(),e.components);return n?(0,t.jsx)(n,Object.assign({},e,{children:(0,t.jsx)(s,e)})):s(e)}n.default=c,c.__RSPRESS_PAGE_META={},c.__RSPRESS_PAGE_META["3.0.22%2Fen%2Fguide%2Fucp%2Fplugin%2Fdsp_develop%2Fdsp_sample%2Fslam.mdx"]={toc:[{id:"principle-introduction",text:"Principle Introduction",depth:2},{id:"slam-implementation-process",text:"SLAM Implementation Process",depth:2}],title:"SLAM Example Introduction",frontmatter:{}}},95895:function(e,n,i){i(39710);var t=i(85893),a=i(67294),o=i(45687);i(20388);let r={"zh-CN":e=>`\u{9884}\u{8BA1}\u{9605}\u{8BFB}\u{65F6}\u{95F4}: ${e.minutes>=1?`${Math.ceil(e.minutes)} \u{5206}\u{949F}`:"\u5C0F\u4E8E 1 \u5206\u949F"}`,"en-US":e=>`Estimated reading time: ${e.minutes>=1?`${Math.ceil(e.minutes)} minutes`:"less than 1 minute"}`};function s(e,n,i){let t=Object.keys(r).includes(n)?n:i;return r[t](e)}n.Z=e=>{let{defaultLocale:n="en-US"}=e,i=(0,o.Vi)().page.readingTimeData,r=(0,o.Jr)(),c=(0,o.e7)(),[p,d]=(0,a.useState)(s(i,r,n));return(0,a.useEffect)(()=>{d(s(i,r,n))},[r,i]),(0,t.jsx)("span",{"data-dark":String(c),className:"rp-reading-time",children:p})}}}]);