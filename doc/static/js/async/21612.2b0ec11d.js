"use strict";(self.webpackChunkrspress_doc_template=self.webpackChunkrspress_doc_template||[]).push([["21612"],{21856:function(e,n,s){e.exports=s.p+"static/image/data_format.ec03be85.png"},20661:function(e,n,s){e.exports=s.p+"static/image/stride_intro.1a1846ce.png"},29300:function(e,n,s){s.r(n);var t=s(85893),i=s(50065),o=s(95895),r=s(21856),a=s(20661);function l(e){let n=Object.assign({h1:"h1",a:"a",p:"p",ul:"ul",li:"li",strong:"strong",pre:"pre",code:"code",span:"span"},(0,i.ah)(),e.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.h1,{id:"key-concepts",children:[(0,t.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#key-concepts",children:"#"}),"Key Concepts"]}),"\n",(0,t.jsx)(o.Z,{}),"\n",(0,t.jsx)(n.p,{children:"This section provides you with some concepts that may appear frequently within the following as well as some commonly used background knowledge."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Original floating-point model"})}),"\n",(0,t.jsx)(n.p,{children:"Available models obtained from the DL framework training like TensorFlow, PyTorch, etc. This model is computed with a precision of float32."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Board-side Deployable Model(HBM model)"})}),"\n",(0,t.jsx)(n.p,{children:"A model format suitable for running on the Horizon computing platform.\r\nIt can support model execution on both ARM CPU and BPU.\r\nSince the operation speed on the BPU will be much faster than that on the CPU, the operators will be computed on the BPU as much as possible.\r\nFor operators that are not supported on the BPU at the moment, they will be computed on the CPU."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Operator"})}),"\n",(0,t.jsx)(n.p,{children:"Deep learning algorithm are composed of computational units, we call these computational units as the Operator (also known as op).\r\nThe operator is a mapping from a function space onto a function space, the name of the operator is unique in the same model, but more than one operator of the same type can exist. For example, Conv1, Conv2, are two different operators with the same operator type."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Model conversion"})}),"\n",(0,t.jsx)(n.p,{children:"Process of converting the original floating-point model or the standard-compliant onnx model into a Horizon hybrid heterogeneous model."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Model quantization"})}),"\n",(0,t.jsx)(n.p,{children:'Currently one of the most effective model optimization methods in industry.\r\nQuantization is to establish data mapping relationships between fixed-point data and floating-point data to achieve inference performance gains with little precision loss,\r\nwhich can be simply understood as using "low-bit" numbers to represent FP32 or other types of values, e.g., FP32 --\x3e INT8 can achieve 4 times parameter compression, and faster calculations can be achived while memory usage is reduced.'}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"The Quantize node is used to quantize the input data of the model from the [float] type to [int8]\r\ntype, which uses the following formula:"}),"\n",(0,t.jsx)(n.pre,{className:"code",children:(0,t.jsx)(n.pre,{className:"shiki css-variables has-line-number",style:{backgroundColor:"var(--shiki-color-background)"},tabIndex:"0",children:(0,t.jsxs)(n.code,{className:"language-text",meta:"",children:[(0,t.jsx)(n.span,{className:"line line-number",children:(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"qx = clamp(round(x / scale) + zero_point, -128, 127)"})}),"\n",(0,t.jsx)(n.span,{className:"line",children:(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"}})})]})})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"round(x)"})," rounds the floating point number."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"clamp(x)"})," clamps the data to an integer value between -128 and 127."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"scale"})," is the quantized scale factor."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"zero_point"})," is the asymmetric quantization zero-point offset value. When in symmetric quantization, ",(0,t.jsx)(n.code,{children:"zero_point = 0"}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"The C++ reference implementation is as follows:"}),"\n",(0,t.jsx)(n.pre,{className:"code",children:(0,t.jsx)(n.pre,{className:"shiki css-variables has-line-number",style:{backgroundColor:"var(--shiki-color-background)"},tabIndex:"0",children:(0,t.jsxs)(n.code,{className:"language-cpp",meta:"",children:[(0,t.jsxs)(n.span,{className:"line line-number",children:[(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"static"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"inline"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"float32_t"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"_round"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"("}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"float32_t"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"const"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" input) {"})]}),"\n",(0,t.jsxs)(n.span,{className:"line line-number",children:[(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  std"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-punctuation)"},children:"::"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"fesetround"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"(FE_TONEAREST);"})]}),"\n",(0,t.jsxs)(n.span,{className:"line line-number",children:[(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"float32_t"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"const"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" result{std"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-punctuation)"},children:"::"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"nearbyintf"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"(input)};"})]}),"\n",(0,t.jsxs)(n.span,{className:"line line-number",children:[(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"return"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" result;"})]}),"\n",(0,t.jsx)(n.span,{className:"line line-number",children:(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"}"})}),"\n",(0,t.jsxs)(n.span,{className:"line line-number",children:[(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"static"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"inline"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"int8_t"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"int_quantize"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"("}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"float32_t"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" value"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-punctuation)"},children:","}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"float32_t"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"const"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" scale) {"})]}),"\n",(0,t.jsxs)(n.span,{className:"line line-number",children:[(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  value "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"="}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"_round"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"(value "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"/"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" scale);"})]}),"\n",(0,t.jsxs)(n.span,{className:"line line-number",children:[(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  value "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"="}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" std"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-punctuation)"},children:"::"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"min"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"(std"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-punctuation)"},children:"::"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"max"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"(value"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-punctuation)"},children:","}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"-"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"128.0"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"f"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:")"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-punctuation)"},children:","}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"127.0"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"f"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:");"})]}),"\n",(0,t.jsxs)(n.span,{className:"line line-number",children:[(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"return"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"static_cast<int8_t>"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"(value);"})]}),"\n",(0,t.jsx)(n.span,{className:"line line-number",children:(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"}"})}),"\n"]})})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["The Dequantize node is used to dequantize output data of the model from the ",(0,t.jsx)(n.code,{children:"int8"})," or ",(0,t.jsx)(n.code,{children:"int32"})," type back to ",(0,t.jsx)(n.code,{children:"float"})," or ",(0,t.jsx)(n.code,{children:"double"})," type with the following formula:"]}),"\n",(0,t.jsx)(n.pre,{className:"code",children:(0,t.jsx)(n.pre,{className:"shiki css-variables has-line-number",style:{backgroundColor:"var(--shiki-color-background)"},tabIndex:"0",children:(0,t.jsxs)(n.code,{className:"language-text",meta:"",children:[(0,t.jsx)(n.span,{className:"line line-number",children:(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"deqx = (x - zero_point) * scale"})}),"\n",(0,t.jsx)(n.span,{className:"line",children:(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"}})})]})})}),"\n",(0,t.jsx)(n.p,{children:"The C++ reference implementation is as follows."}),"\n",(0,t.jsx)(n.pre,{className:"code",children:(0,t.jsx)(n.pre,{className:"shiki css-variables has-line-number",style:{backgroundColor:"var(--shiki-color-background)"},tabIndex:"0",children:(0,t.jsxs)(n.code,{className:"language-cpp",meta:"",children:[(0,t.jsxs)(n.span,{className:"line line-number",children:[(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"static_cast<float>"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"(value) "}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"*"}),(0,t.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" scale"})]}),"\n"]})})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"PTQ"})}),"\n",(0,t.jsxs)(n.p,{children:["PTQ conversion scheme, a quantization method that first trains a floating-point model and then uses a calibration image to calculate quantization parameters to convert the floating-point model into a quantized model.\r\nFor more details, refer to the ",(0,t.jsx)(n.a,{href:"/3.0.22/en/guide/faststart/ptq_qat_overview.html",children:"PTQ and QAT Introduction"})," section."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"QAT"})}),"\n",(0,t.jsxs)(n.p,{children:["QAT (quantization-aware training) scheme, which intervenes in the floating-point model structure during the floating-point training to enable the model to perceive the loss from quantization and reduce the quantization loss accuracy.\r\nFor more details, refer to the ",(0,t.jsx)(n.a,{href:"/3.0.22/en/guide/faststart/ptq_qat_overview.html",children:"PTQ and QAT Introduction"})," section."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Tensor"})}),"\n",(0,t.jsx)(n.p,{children:"The Tensor is a multidimensional array with a uniform data type, as a container for the data computed by the operator, it contains the input and output data.\r\nThe carrier of tensor specific information, contains the name, shape, data layout, data type, etc. of the tensor data."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Data layout"})}),"\n",(0,t.jsx)(n.p,{children:"In the deep learning, multidimensional data is stored through the multidimensional array (tensor), and the generic neural network featuremaps are usually stored using the four-dimensional array (i.e., 4D) format, i.e., the following four dimensions:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"N: The number of Batch, e.g. the number of images."}),"\n",(0,t.jsx)(n.li,{children:"H: Height, the height of the image\u3002"}),"\n",(0,t.jsx)(n.li,{children:"W: Width, the weight of the image\u3002"}),"\n",(0,t.jsx)(n.li,{children:"C: Channel, the number of channels of the image."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"However, the data can only be stored linearly, so the four dimensions have a corresponding order, and different layout formats of the data will affect the computational performance.\r\nThe common data storage formats are NCHW and NHWC:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"NCHW: It stores all the pixel values of the same channel in order."}),"\n",(0,t.jsx)(n.li,{children:"NHWC: It stores the pixel values of the same position of different channels in order."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"As shown below:"}),"\n",(0,t.jsx)("img",{src:r,alt:"data_format",height:"600",width:"600"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Data type"})}),"\n",(0,t.jsx)(n.p,{children:"The image data types commonly used below include rgb, bgr, gray, yuv444, nv12, and featuremap."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"The rgb, bgr, and gray are commonly used image format. Note that each value is represented using UINT8."}),"\n",(0,t.jsx)(n.li,{children:"The yuv444 is also a popular image format. Note that each value is represented using UINT8."}),"\n",(0,t.jsx)(n.li,{children:"The NV12 is a popular YUV420 image format. note that each value is represented using UINT8."}),"\n",(0,t.jsx)(n.li,{children:"The Featuremap is suitable for cases where the above listed formats failed to meet your needs, and this type uses float32 for each value.\r\nFor example, this format is commonly used for model processing such as radar and speech."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Batch, Batch Size"})}),"\n",(0,t.jsx)(n.p,{children:"In the model training process, a set of training samples used in each iteration is called a batch.\r\nThe batch size refers to the number of samples that the model processes in each iteration."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Cosine similarity"})}),"\n",(0,t.jsx)(n.p,{children:"One of the accuracy comparison algorithms, the computation result takes the value range of [-1,1],\r\nif the result of the comparison is closer to 1, it means that the value of the two is more similar,\r\nand the closer to -1 means that the value of the two is more opposite."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Stride"})}),"\n",(0,t.jsx)(n.p,{children:"Stride is the actual size of the space occupied by each line of an image when it is stored in memory.\r\nMost computer processors work with 32-bit or 64-bit, so the processor will read the complete amount of data at a time,\r\npreferably in multiples of 4 bytes or 8 bytes, if other values, the computer will need to specialize in processing, which will lead to a reduction in efficiency.\r\nIn order to efficiently process the images by the computer, it is common to fill in some extra data on top of the original data to achieve 4-byte or 8-byte alignment.\r\nThe operation of alignment is also called Padding, and the actual alignment rules depend on the specific hardware and software system."}),"\n",(0,t.jsx)("img",{src:a,width:"600"}),"\n",(0,t.jsx)(n.p,{children:"Suppose we have an 8-bit deep grayscale image with a height (Height) of 20 pixels and a width (Width) of 30 pixels, then the effective data per line of the image is 30 bytes,\r\nand if the computer's alignment rule is 8 bytes, then the span of the image after alignment is 32 bytes, at which point the amount of data that needs to be Padding per line is 2 bytes."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Calibration dataset"})}),"\n",(0,t.jsx)(n.p,{children:"The dataset used to do forward inference in the PTQ scenario. The distribution of this dataset represents the distribution of all datasets and should be representative when obtaining the calibration set.\r\nIf the dataset is not the model-matched dataset or is not representative enough, the quantization factor computed from the calibration set performs poorly on the full dataset, with high quantization loss and low accuracy after quantization."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["For more information about abbreviations in the documents, please refer to the section ",(0,t.jsx)(n.a,{href:"/3.0.22/en/guide/appendix/common_abbreviations.html",children:"Common Abbreviations"}),"."]})]})}function c(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:n}=Object.assign({},(0,i.ah)(),e.components);return n?(0,t.jsx)(n,Object.assign({},e,{children:(0,t.jsx)(l,e)})):l(e)}n.default=c,c.__RSPRESS_PAGE_META={},c.__RSPRESS_PAGE_META["3.0.22%2Fen%2Fguide%2Fkey_concept.mdx"]={toc:[],title:"Key Concepts",frontmatter:{}}},95895:function(e,n,s){s(39710);var t=s(85893),i=s(67294),o=s(45687);s(20388);let r={"zh-CN":e=>`\u{9884}\u{8BA1}\u{9605}\u{8BFB}\u{65F6}\u{95F4}: ${e.minutes>=1?`${Math.ceil(e.minutes)} \u{5206}\u{949F}`:"\u5C0F\u4E8E 1 \u5206\u949F"}`,"en-US":e=>`Estimated reading time: ${e.minutes>=1?`${Math.ceil(e.minutes)} minutes`:"less than 1 minute"}`};function a(e,n,s){let t=Object.keys(r).includes(n)?n:s;return r[t](e)}n.Z=e=>{let{defaultLocale:n="en-US"}=e,s=(0,o.Vi)().page.readingTimeData,r=(0,o.Jr)(),l=(0,o.e7)(),[c,h]=(0,i.useState)(a(s,r,n));return(0,i.useEffect)(()=>{h(a(s,r,n))},[r,s]),(0,t.jsx)("span",{"data-dark":String(l),className:"rp-reading-time",children:c})}}}]);