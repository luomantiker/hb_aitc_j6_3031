"use strict";(self.webpackChunkrspress_doc_template=self.webpackChunkrspress_doc_template||[]).push([["95956"],{21987:function(e,n,t){t.r(n);var o=t(85893),i=t(50065),r=t(95895);function s(e){let n=Object.assign({h1:"h1",a:"a",p:"p",ul:"ul",li:"li",div:"div",code:"code",h2:"h2",pre:"pre",span:"span"},(0,i.ah)(),e.components);return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(n.h1,{id:"model-performance-optimization",children:[(0,o.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#model-performance-optimization",children:"#"}),"Model Performance Optimization"]}),"\n",(0,o.jsx)(r.Z,{}),"\n",(0,o.jsx)(n.p,{children:"Based on previous performance analysis, you may find that the performance results are less than expected.\nThis section covers Horizon's recommendations and measures to improve model performance, including:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Check Those Performance-affecting YAML Configuration Parameters;"}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"CPU OP Processing;"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.div,{className:"rspress-directive info",children:[(0,o.jsx)(n.div,{className:"rspress-directive-title",children:"Note"}),(0,o.jsx)(n.div,{className:"rspress-directive-content",children:(0,o.jsxs)(n.p,{children:["Checking yaml configuration parameters and CPU OP Processing only apply to usage scenarios where the model is compiled by using ",(0,o.jsx)(n.code,{children:"hb_compile"}),"."]})})]}),"\n",(0,o.jsx)(n.p,{children:"Because some optimizations may influence the parameter space of the original floating-point model, in other words, it may cause model retraining. To prevent the costs of repeated adjustments and retraining brought about by model performance optimization, we suggest that you use random parameters to export models and validate performance before getting satisfactory model performance."}),"\n",(0,o.jsxs)(n.h2,{id:"check-those-performance-affecting-yaml-configuration-parameters",children:[(0,o.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#check-those-performance-affecting-yaml-configuration-parameters",children:"#"}),"Check Those Performance-affecting YAML Configuration Parameters"]}),"\n",(0,o.jsxs)(n.p,{children:["Some parameters in the model conversion configuration file can affect model's final performance, you can check if they've been correctly specified as you expected.\nThe definitions and functions of all parameters please refer to the ",(0,o.jsx)(n.a,{href:"/3.0.22/en/guide/ptq/ptq_tool/hb_compile/convert.html#config_parameter",children:"Specific Parameter Information"})," section."]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"debug_mode"})," parameter is used for accuracy debugging analysis.\nIf ",(0,o.jsx)(n.code,{children:"dump_all_layers_output"})," is configured, a dequantized output node will be added to each convolutional and matmul operator to dump the intermediate results in model conversion. It will significantly reduce model's onboard performance. Therefore, please remember to remove the ",(0,o.jsx)(n.code,{children:"dump_all_layers_output"})," parameter from ",(0,o.jsx)(n.code,{children:"debug_mode"})," in performance evaluation."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"compile_mode"})," parameter is used to select whether the optimization direction is bandwidth or latency when compiling the model.\nIf you are concerned about performance, please configure it as ",(0,o.jsx)(n.code,{children:"latency"}),"."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"optimize_level"})," parameter is used to select the optimization level of the compiler. O0: No optimization, fastest compilation speed and lowest optimization level.\nO1 to O2: As the optimization level increases, the compiled model is expected to execute faster, but the compilation time is also expected to be longer."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"max_time_per_fc"})," parameter is used to control the execution time of the function-call of the compiled model data instruction, thus implementing the model priority preemption function.\nSetting this parameter to change the execution time of the function-call of the preempted model will affect the on-board performance of the model."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.h2,{id:"cpu-op-processing",children:[(0,o.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#cpu-op-processing",children:"#"}),"CPU OP Processing"]}),"\n",(0,o.jsxs)(n.p,{children:["If the evaluation of hrt_model_exec perf confirms that the apparent performance bottleneck is due to the current operator running on the CPU.\nThen in such case, we suggest that you should confirm if the OPs which currently running on the CPU can be supported by the BPU as described in the ",(0,o.jsx)(n.a,{href:"/3.0.22/en/guide/appendix/supported_op_list/onnx_operator_support_list.html",children:"Toolchain Operator Support Constraint List-ONNX Operator Support List"})," section."]}),"\n",(0,o.jsxs)(n.p,{children:["If the operator parameters used are outside the constraints supported by the BPU, we suggest that you adjust the corresponding computing parameters of the original floating-point model back into the restricted range.\nTo help you quickly find out the off-limits parameter(s), we suggest that you proceed the model check procedure as described in the ",(0,o.jsx)(n.a,{href:"/3.0.22/en/guide/ptq/ptq_usage/check_model.html",children:"Check the Model"})," section, the tool will print out the off-limits parameters at the console."]}),"\n",(0,o.jsxs)(n.div,{className:"rspress-directive info",children:[(0,o.jsx)(n.div,{className:"rspress-directive-title",children:"Note"}),(0,o.jsx)(n.div,{className:"rspress-directive-content",children:(0,o.jsxs)(n.p,{children:["Note that you'll need to handle the effect on model performance (if any) caused by modifying the original Floating-point model parameters.\nTake the ",(0,o.jsx)(n.code,{children:"input_channel"})," or ",(0,o.jsx)(n.code,{children:"output_channel"})," of Convolution exceeding restrictions as classic examples, by reducing number of channels to quickly enable the OP to be supported by the BPU can also affect model accuracy."]})})]}),"\n",(0,o.jsx)(n.p,{children:"If the operator does not have BPU support, you need to optimize it according to the following conditions:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"CPU operator at the middle of the model"}),"\n",(0,o.jsx)(n.p,{children:"For cases where the CPU operator is in the middle of the model, it is recommended that you try parameter adjustment, operator replacement or model modification as a priority."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"CPU operator at the beginning and end of the model"}),"\n",(0,o.jsx)(n.p,{children:"For the case where the CPU operator is at the beginning and end of the model, please refer to the following example, using the quantization/anti-quantization nodes as an example."}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["For nodes connected to the model input and output, you can add the ",(0,o.jsx)(n.code,{children:"remove_node_type"})," parameter to the yaml file model_parameters configuration group (model parameters group) and recompile the model."]}),"\n",(0,o.jsx)(n.pre,{className:"code",children:(0,o.jsx)(n.pre,{className:"shiki css-variables has-line-number",style:{backgroundColor:"var(--shiki-color-background)"},tabIndex:"0",children:(0,o.jsxs)(n.code,{className:"language-yaml",meta:"",children:[(0,o.jsxs)(n.span,{className:"line line-number",children:[(0,o.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"remove_node_type"}),(0,o.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,o.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,o.jsx)(n.span,{style:{color:"var(--shiki-token-string-expression)"},children:'"Quantize; Dequantize"'})]}),"\n"]})})}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}function a(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:n}=Object.assign({},(0,i.ah)(),e.components);return n?(0,o.jsx)(n,Object.assign({},e,{children:(0,o.jsx)(s,e)})):s(e)}n.default=a,a.__RSPRESS_PAGE_META={},a.__RSPRESS_PAGE_META["3.0.22%2Fen%2Fguide%2Fperformance_tune.mdx"]={toc:[{id:"check-those-performance-affecting-yaml-configuration-parameters",text:"Check Those Performance-affecting YAML Configuration Parameters",depth:2},{id:"cpu-op-processing",text:"CPU OP Processing",depth:2}],title:"Model Performance Optimization",frontmatter:{}}},95895:function(e,n,t){t(39710);var o=t(85893),i=t(67294),r=t(45687);t(20388);let s={"zh-CN":e=>`\u{9884}\u{8BA1}\u{9605}\u{8BFB}\u{65F6}\u{95F4}: ${e.minutes>=1?`${Math.ceil(e.minutes)} \u{5206}\u{949F}`:"\u5C0F\u4E8E 1 \u5206\u949F"}`,"en-US":e=>`Estimated reading time: ${e.minutes>=1?`${Math.ceil(e.minutes)} minutes`:"less than 1 minute"}`};function a(e,n,t){let o=Object.keys(s).includes(n)?n:t;return s[o](e)}n.Z=e=>{let{defaultLocale:n="en-US"}=e,t=(0,r.Vi)().page.readingTimeData,s=(0,r.Jr)(),c=(0,r.e7)(),[l,d]=(0,i.useState)(a(t,s,n));return(0,i.useEffect)(()=>{d(a(t,s,n))},[s,t]),(0,o.jsx)("span",{"data-dark":String(c),className:"rp-reading-time",children:l})}}}]);