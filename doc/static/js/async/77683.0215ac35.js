"use strict";(self.webpackChunkrspress_doc_template=self.webpackChunkrspress_doc_template||[]).push([["77683"],{4774:function(e,i,n){n.r(i);var s=n(85893),r=n(50065),t=n(95895);function d(e){let i=Object.assign({h1:"h1",a:"a",p:"p",pre:"pre",code:"code",span:"span",h2:"h2",ul:"ul",li:"li",ol:"ol",div:"div"},(0,r.ah)(),e.components);return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(i.h1,{id:"config-file",children:[(0,s.jsx)(i.a,{className:"header-anchor","aria-hidden":"true",href:"#config-file",children:"#"}),"Config File"]}),"\n",(0,s.jsx)(t.Z,{}),"\n",(0,s.jsx)(i.p,{children:"Training a model using the HAT algorithm toolkit is usually done with a single command:"}),"\n",(0,s.jsx)(i.pre,{className:"code",children:(0,s.jsx)(i.pre,{className:"shiki css-variables has-line-number",style:{backgroundColor:"var(--shiki-color-background)"},tabIndex:"0",children:(0,s.jsxs)(i.code,{className:"language-bash",meta:"",children:[(0,s.jsxs)(i.span,{className:"line line-number",children:[(0,s.jsx)(i.span,{style:{color:"var(--shiki-token-function)"},children:"python3"}),(0,s.jsx)(i.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,s.jsx)(i.span,{style:{color:"var(--shiki-token-string)"},children:"tools/train.py"}),(0,s.jsx)(i.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,s.jsx)(i.span,{style:{color:"var(--shiki-token-string)"},children:"--stage"}),(0,s.jsx)(i.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,s.jsx)(i.span,{style:{color:"var(--shiki-token-string)"},children:"TRAINING_STEPS"}),(0,s.jsx)(i.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,s.jsx)(i.span,{style:{color:"var(--shiki-token-string)"},children:"--config"}),(0,s.jsx)(i.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,s.jsx)(i.span,{style:{color:"var(--shiki-token-string)"},children:"/PATH/TO/CONFIG"})]}),"\n"]})})}),"\n",(0,s.jsxs)(i.p,{children:["In which, ",(0,s.jsx)(i.code,{children:"/PATH/TO/CONFIG"})," is the ",(0,s.jsx)(i.code,{children:"config"})," file for model training, which defines the model structure, dataset loading, and the entire training process."]}),"\n",(0,s.jsxs)(i.p,{children:["This section introduces some fixed global keywords in the ",(0,s.jsx)(i.code,{children:"config"})," file and their configuration descriptions, giving you an overview of the ",(0,s.jsx)(i.code,{children:"config"})," file."]}),"\n",(0,s.jsxs)(i.h2,{id:"global-keywords",children:[(0,s.jsx)(i.a,{className:"header-anchor","aria-hidden":"true",href:"#global-keywords",children:"#"}),"Global Keywords"]}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["training_stage: Stages of model training, including ",(0,s.jsx)(i.code,{children:"float"}),", ",(0,s.jsx)(i.code,{children:"qat"}),", and ",(0,s.jsx)(i.code,{children:"int_infer"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:"device_ids: List of GPUs used for model training."}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["cudnn_benchmark: Whether to turn on ",(0,s.jsx)(i.code,{children:"CUDNN"})," benchmark, usually defaults to ",(0,s.jsx)(i.code,{children:"True"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["seed:  Whether to set the random number seed. usually defaults to ",(0,s.jsx)(i.code,{children:"None"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["log_rank_zero_only: Simplifies the log printing in multi-card training by outputting logs only on ",(0,s.jsx)(i.code,{children:"card 0"}),". Usually defaults to ",(0,s.jsx)(i.code,{children:"True"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["model: The structure of the model participating in the ",(0,s.jsx)(i.code,{children:"training"})," process. ",(0,s.jsx)(i.code,{children:"type"})," is the type of the model, e.g., ",(0,s.jsx)(i.code,{children:"Classifier"}),", ",(0,s.jsx)(i.code,{children:"Segmentor"}),", ",(0,s.jsx)(i.code,{children:"RetinaNet"}),", etc., corresponding to a type of models in classification, segmentation, and detection, respectively. It will be built into a specific class in the process, and other parameters are all used to initialize this class."]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["deploy_model: The model structure that participates in the ",(0,s.jsx)(i.code,{children:"deploy"})," process, mainly used for model compilation. Compared to ",(0,s.jsx)(i.code,{children:"model"}),", in most cases you only need to set the loss function and the post-processing part to ",(0,s.jsx)(i.code,{children:"None"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["deploy_inputs: Simulated inputs for the ",(0,s.jsx)(i.code,{children:"deploy"})," procedure. Values do not matter here, just make sure the format meets the input requirements."]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["data_loader: Dataset loading process in the training phase. Its ",(0,s.jsx)(i.code,{children:"type"})," is a specific class ",(0,s.jsx)(i.code,{children:"torch.utils.data.DataLoader"}),", and other parameters are all used to initialize this class. You can also read the interface documents on the ",(0,s.jsx)(i.code,{children:"Pytorch"})," website to learn these parameters. Here ",(0,s.jsx)(i.code,{children:"dataset"})," means to read a specific dataset, e.g., ",(0,s.jsx)(i.code,{children:"ImageNet"}),", ",(0,s.jsx)(i.code,{children:"MSCOCO"}),", ",(0,s.jsx)(i.code,{children:"VOC"}),", etc., and ",(0,s.jsx)(i.code,{children:"transforms"})," means data enhancement operations added when reading the data."]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["val_data_loader: The dataset loading process in the phase of validating model performance. Different from ",(0,s.jsx)(i.code,{children:"data_loader"}),", its ",(0,s.jsx)(i.code,{children:"data_path"})," is different and the processes of ",(0,s.jsx)(i.code,{children:"transforms"})," and ",(0,s.jsx)(i.code,{children:"sample"})," are removed."]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["batch_processor: Operations performed by the model at each iteration ",(0,s.jsx)(i.code,{children:"stage"})," during the training, including forward propagation, backward propagation, parameter update, etc. The ",(0,s.jsx)(i.code,{children:"batch_transforms"})," parameter, if included, indicates that some data enhancement operations are performed on the ",(0,s.jsx)(i.code,{children:"GPU"}),", which can greatly speed up the training."]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["val_batch_processor: The operations performed by the model at each iteration ",(0,s.jsx)(i.code,{children:"stage"})," during the validation process, containing only forward propagation."]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["metric_updater: Metric updating method of the model during model training, which is used to verify whether the performance of the training model is improving. It is usually used together with ",(0,s.jsx)(i.code,{children:"train_metrics"})," under ",(0,s.jsx)(i.code,{children:"float_trainer"}),". ",(0,s.jsx)(i.code,{children:"train_metrics"})," is the specific form of the metric, while ",(0,s.jsx)(i.code,{children:"metric_updater"})," just provides an updating method."]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["val_metric_updater: Metric updating method of the trained model during the performance validation process, which is used to verify the final performance of the trained model. Similar to ",(0,s.jsx)(i.code,{children:"metric_updater"}),", it is usually used together with ",(0,s.jsx)(i.code,{children:"val_metrics"})," under ",(0,s.jsx)(i.code,{children:"float_trainer"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["float_trainer: Configuration of the floating-point model training process. Its ",(0,s.jsx)(i.code,{children:"type"})," is ",(0,s.jsx)(i.code,{children:"distributed_data_parallel_trainer"}),", which means distributed training is supported. Other parameters define the model, dataset loading, optimizer, training ",(0,s.jsx)(i.code,{children:"epoch"})," length, etc., where ",(0,s.jsx)(i.code,{children:"callbacks"})," represents the operations performed in the training, such as model saving, learning rate update, precision validation, etc. It is a variable directly called by the ",(0,s.jsx)(i.code,{children:"tools/train.py"})," file."]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["qat_trainer: Configuration for the ",(0,s.jsx)(i.code,{children:"QAT"})," model training process. This parameter basically means the same as ",(0,s.jsx)(i.code,{children:"float_trainer"}),". It is a variable directly called by the ",(0,s.jsx)(i.code,{children:"tools/train.py"})," file."]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["int_infer_trainer: With no training processes included, it is only used to verify the accuracy of the fixed-point model. It is a variable directly called by the ",(0,s.jsx)(i.code,{children:"tools/train.py"})," file."]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["compile_cfg: Compile-related configuration. ",(0,s.jsx)(i.code,{children:"out_dir"})," is the output path of the compiled ",(0,s.jsx)(i.code,{children:"HBM"})," file (deployment model)."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.p,{children:["The reason why these variables are called global keywords is that they are defined in almost every ",(0,s.jsx)(i.code,{children:"config"})," file and basically carry the same functions. By reading this document, you can get a general idea of what a ",(0,s.jsx)(i.code,{children:"config"})," file can do."]}),"\n",(0,s.jsxs)(i.h2,{id:"configuration",children:[(0,s.jsx)(i.a,{className:"header-anchor","aria-hidden":"true",href:"#configuration",children:"#"}),"Configuration"]}),"\n",(0,s.jsxs)(i.p,{children:["This section describes the configuration of the global keyword for the data type ",(0,s.jsx)(i.code,{children:"dict"}),"."]}),"\n",(0,s.jsxs)(i.p,{children:["Global keywords of the ",(0,s.jsx)(i.code,{children:"dict"})," type can be further divided into the following two types:"]}),"\n",(0,s.jsxs)(i.ol,{children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["Those with ",(0,s.jsx)(i.code,{children:"type"}),", such as ",(0,s.jsx)(i.code,{children:"model"}),", ",(0,s.jsx)(i.code,{children:"data_loader"}),", ",(0,s.jsx)(i.code,{children:"float_trainer"}),", etc."]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["Those without ",(0,s.jsx)(i.code,{children:"type"}),", such as ",(0,s.jsx)(i.code,{children:"compile_cfg"}),", etc."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.p,{children:["The difference is that a global keyword that contains ",(0,s.jsx)(i.code,{children:"type"})," is essentially a ",(0,s.jsx)(i.code,{children:"class"})," whose ",(0,s.jsx)(i.code,{children:"type"})," value can be either a ",(0,s.jsx)(i.code,{children:"string"})," variable or a specific ",(0,s.jsx)(i.code,{children:"class"}),", and even if it is a ",(0,s.jsx)(i.code,{children:"string"}),", it will eventually be built into a corresponding ",(0,s.jsx)(i.code,{children:"class"})," at runtime. The values of all the keys in the dict except ",(0,s.jsx)(i.code,{children:"type"})," are used to initialize this ",(0,s.jsx)(i.code,{children:"class"}),". Similar to global keywords, these keys can be either a numeric value or a dict containing a ",(0,s.jsx)(i.code,{children:"type"})," variable, such as the dataset property in ",(0,s.jsx)(i.code,{children:"data_loader"}),", and the ",(0,s.jsx)(i.code,{children:"transforms"})," property under this ",(0,s.jsx)(i.code,{children:"dataset"}),"."]}),"\n",(0,s.jsxs)(i.p,{children:["For a global keyword without a ",(0,s.jsx)(i.code,{children:"type"})," variable, it is a regular ",(0,s.jsx)(i.code,{children:"dict"})," variable, and the code will get the corresponding ",(0,s.jsx)(i.code,{children:"values"})," from its ",(0,s.jsx)(i.code,{children:"keys"})," during runtime."]}),"\n",(0,s.jsxs)(i.div,{className:"rspress-directive tip",children:[(0,s.jsx)(i.div,{className:"rspress-directive-title",children:"Hint"}),(0,s.jsx)(i.div,{className:"rspress-directive-content",children:(0,s.jsx)(i.p,{children:"All provided configurations are guaranteed to work properly and reproduce the accuracy. If you need to modify the configuration due to the environment or training time, then you may need to change the training strategy as well. Directly modifying individual configurations in the config file sometimes may not lead to desired results."})})]})]})}function a(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:i}=Object.assign({},(0,r.ah)(),e.components);return i?(0,s.jsx)(i,Object.assign({},e,{children:(0,s.jsx)(d,e)})):d(e)}i.default=a,a.__RSPRESS_PAGE_META={},a.__RSPRESS_PAGE_META["3.0.22%2Fen%2Fguide%2Fadvanced_content%2Fhat%2Ftutorials%2Fconfig.mdx"]={toc:[{id:"global-keywords",text:"Global Keywords",depth:2},{id:"configuration",text:"Configuration",depth:2}],title:"Config File",frontmatter:{}}},95895:function(e,i,n){n(39710);var s=n(85893),r=n(67294),t=n(45687);n(20388);let d={"zh-CN":e=>`\u{9884}\u{8BA1}\u{9605}\u{8BFB}\u{65F6}\u{95F4}: ${e.minutes>=1?`${Math.ceil(e.minutes)} \u{5206}\u{949F}`:"\u5C0F\u4E8E 1 \u5206\u949F"}`,"en-US":e=>`Estimated reading time: ${e.minutes>=1?`${Math.ceil(e.minutes)} minutes`:"less than 1 minute"}`};function a(e,i,n){let s=Object.keys(d).includes(i)?i:n;return d[s](e)}i.Z=e=>{let{defaultLocale:i="en-US"}=e,n=(0,t.Vi)().page.readingTimeData,d=(0,t.Jr)(),o=(0,t.e7)(),[c,l]=(0,r.useState)(a(n,d,i));return(0,r.useEffect)(()=>{l(a(n,d,i))},[d,n]),(0,s.jsx)("span",{"data-dark":String(o),className:"rp-reading-time",children:c})}}}]);