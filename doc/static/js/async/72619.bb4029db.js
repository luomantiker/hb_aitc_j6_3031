"use strict";(self.webpackChunkrspress_doc_template=self.webpackChunkrspress_doc_template||[]).push([["72619"],{38120:function(e,n,i){i.r(n);var s=i(85893),t=i(50065),l=i(95895);function c(e){let n=Object.assign({h1:"h1",a:"a",p:"p",strong:"strong",h2:"h2",ul:"ul",li:"li"},(0,t.ah)(),e.components);return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(n.h1,{id:"overview",children:[(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#overview",children:"#"}),"Overview"]}),"\n",(0,s.jsx)(l.Z,{}),"\n",(0,s.jsx)(n.p,{children:"Horizon-Torch-Samples is an algorithm tool based on the Pytorch and Pytorch plugin interfaces, which is an efficient and user-friendly algorithm toolkit for Horizon BPUs."}),"\n",(0,s.jsx)(n.p,{children:"PyTorch, on which Horizon-Torch-Samples relies, is a tensor library optimized for deep learning by using GPUs and CPUs, which is now one of the most popular deep learning frameworks. The Pytorch plugin is a set of quantization algorithm tools developed based on Pytorch. Focusing on the implementation of quantization functions close to the computing platform, its quantization algorithms are deeply coupled with Horizon computing platforms, and the quantization models trained with this tool can be compiled and run normally on Horizon BPUs."}),"\n",(0,s.jsxs)(n.p,{children:["As the basic framework of algorithm package developed by Horizon Robotics, Horizon-Torch-Samples is open to all algorithm users, developers, and researchers. Its quantization training is closely related to the Horizon processors and contains a complete process: ",(0,s.jsx)(n.strong,{children:"Floating point training"})," --\x3e ",(0,s.jsx)(n.strong,{children:"QAT training"})," --\x3e ",(0,s.jsx)(n.strong,{children:"Fixed-point transformation prediction"})," --\x3e ",(0,s.jsx)(n.strong,{children:"Model check compilation (for Horizon BPU)"})," --\x3e ",(0,s.jsx)(n.strong,{children:"On-board accuracy simulation verification"}),". It also provides state-of-the-art (SOTA) deep-learning models for common image tasks including classification, detection, segmentation, etc."]}),"\n",(0,s.jsxs)(n.h2,{id:"features",children:[(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#features",children:"#"}),"Features"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Based on Pytorch and horizon_plugin_pytorch."}),"\n",(0,s.jsxs)(n.li,{children:["Include a complete process from ",(0,s.jsx)(n.strong,{children:"Floating point training"})," to ",(0,s.jsx)(n.strong,{children:"On-board accuracy simulation verification"}),"."]}),"\n",(0,s.jsx)(n.li,{children:"Include SOTA models for common image tasks such as classification, detection, and segmentation. All samples are compatible with Horizon BPUs."}),"\n"]}),"\n",(0,s.jsxs)(n.h2,{id:"sample-models",children:[(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#sample-models",children:"#"}),"Sample Models"]}),"\n",(0,s.jsx)(n.p,{children:"Horizon-Torch-Samples currently includes the following deep learning models:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Classification Model"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"mobilenetv1_imagenet"}),"\n",(0,s.jsx)(n.li,{children:"mobilenetv2_imagenet"}),"\n",(0,s.jsx)(n.li,{children:"resnet18_imagenet"}),"\n",(0,s.jsx)(n.li,{children:"resnet50_imagenet"}),"\n",(0,s.jsx)(n.li,{children:"vargnetv2_imagenet"}),"\n",(0,s.jsx)(n.li,{children:"efficientnet_imagenet"}),"\n",(0,s.jsx)(n.li,{children:"horizon_swin_transformer_imagenet"}),"\n",(0,s.jsx)(n.li,{children:"mixvargenet_imagenet"}),"\n",(0,s.jsx)(n.li,{children:"efficientnasnetm_imagenet"}),"\n",(0,s.jsx)(n.li,{children:"efficientnasnets_imagenet"}),"\n",(0,s.jsx)(n.li,{children:"vit_small_imagenet"}),"\n",(0,s.jsx)(n.li,{children:"henet_tinye_imagenet"}),"\n",(0,s.jsx)(n.li,{children:"henet_tinym_imagenet"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Detection model"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"fcos_efficientnetb0_mscoco"}),"\n",(0,s.jsx)(n.li,{children:"fcos_efficientnetb1_mscoco"}),"\n",(0,s.jsx)(n.li,{children:"fcos_efficientnetb2_mscoco"}),"\n",(0,s.jsx)(n.li,{children:"fcos_efficientnetb3_mscoco"}),"\n",(0,s.jsx)(n.li,{children:"detr_resnet50_mscoco"}),"\n",(0,s.jsx)(n.li,{children:"detr_efficientnetb3_mscoco"}),"\n",(0,s.jsx)(n.li,{children:"deform_detr_resnet50_mscoco"}),"\n",(0,s.jsx)(n.li,{children:"fcos3d_efficientnetb0_nuscenes"}),"\n",(0,s.jsx)(n.li,{children:"pointpillars_kitti_car"}),"\n",(0,s.jsx)(n.li,{children:"centerpoint_pointpillar_nuscenes"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Segmentation model"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"deeplabv3plus_efficientnetm0_cityscapes"}),"\n",(0,s.jsx)(n.li,{children:"deeplabv3plus_efficientnetm1_cityscapes"}),"\n",(0,s.jsx)(n.li,{children:"deeplabv3plus_efficientnetm2_cityscapes"}),"\n",(0,s.jsx)(n.li,{children:"fastscnn_efficientnetb0tiny_cityscapes"}),"\n",(0,s.jsx)(n.li,{children:"unet_mobilenetv1_cityscapes"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Optical flow model"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"pwcnet_pwcnetneck_flyingchairs"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Lane detection model"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"ganet_mixvargenet_culane"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Multiple Object Track"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"motr_efficientnetb3_mot17"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Binocular Depth Estimation"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"stereonet_stereonetneck_sceneflow"}),"\n",(0,s.jsx)(n.li,{children:"stereonetplus_mixvargenet_sceneflow"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Bev Multi-task Model"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"bev_ipm_efficientnetb0_multitask_nuscenes"}),"\n",(0,s.jsx)(n.li,{children:"bev_lss_efficientnetb0_multitask_nuscenes"}),"\n",(0,s.jsx)(n.li,{children:"bev_gkt_mixvargenet_multitask_nuscenes"}),"\n",(0,s.jsx)(n.li,{children:"bev_ipm_4d_efficientnetb0_multitask_nuscenes"}),"\n",(0,s.jsx)(n.li,{children:"detr3d_efficientnetb3_nuscenes"}),"\n",(0,s.jsx)(n.li,{children:"petr_efficientnetb3_nuscenes"}),"\n",(0,s.jsx)(n.li,{children:"bevformer_tiny_resnet50_detection_nuscenes"}),"\n",(0,s.jsx)(n.li,{children:"bev_cft_efficientnetb3_nuscenes"}),"\n",(0,s.jsx)(n.li,{children:"bev_sparse_henet_tinym_nuscenes"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Keypoints Detection Model"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"keypoint_efficientnetb0_carfusion"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Lidar Multi-task Model"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"centerpoint_mixvargnet_multitask_nuscenes"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Trajectory Prediction Model"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"densetnt_vectornet_argoverse1"}),"\n",(0,s.jsx)(n.li,{children:"qcnet_oe_argoverse2"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Occupancy Prediction Model"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"flashocc_henet_lss_occ3d_nuscenes"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Online Map Construction"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"maptroe_henet_tinym_bevformer_nuscenes"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Lidar Fusion Multi-task Model"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"bevfusion_pointpillar_henet_multisensor_multitask_nuscenes"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["In the above model, 'resnet18_imagenet', 'resnet50_imagenet', 'vargnetv2_imagenet', 'efficientnasnetm_imagenet', 'efficientnasnets_imagenet', 'efficientnet_imagenet', 'mixvargenet_imagenet', 'vargnetv2_imagenet', 'ganet_mixvargenet_culane', 'deeplabv3plus_efficientnetm0_cityscapes', 'deeplabv3plus_efficientnetm1_cityscapes', 'deeplabv3plus_efficientnetm2_cityscapes', 'fastscnn_efficientnetb0tiny_cityscapes', 'bev_gkt_mixvargenet_multitask_nuscenes', 'bev_ipm_efficientnetb0_multitask_nuscenes', 'bev_lss_efficientnetb0_multitask_nuscenes', 'flashocc_henet_lss_occ3d_nuscenes', 'detr3d_efficientnetb3_nuscenes' and 'keypoint_efficientnetb0_carfusion'  only need to do calibration quantization accuracy to achieve the goal, detailed accuracy reference ",(0,s.jsx)(n.a,{href:"/3.0.22/en/guide/advanced_content/hat/model_zoo.html",children:"model_zoo"}),"."]})]})}function r(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:n}=Object.assign({},(0,t.ah)(),e.components);return n?(0,s.jsx)(n,Object.assign({},e,{children:(0,s.jsx)(c,e)})):c(e)}n.default=r,r.__RSPRESS_PAGE_META={},r.__RSPRESS_PAGE_META["3.0.22%2Fen%2Fguide%2Fadvanced_content%2Fhat%2Fintroduction.mdx"]={toc:[{id:"features",text:"Features",depth:2},{id:"sample-models",text:"Sample Models",depth:2}],title:"Overview",frontmatter:{}}},95895:function(e,n,i){i(39710);var s=i(85893),t=i(67294),l=i(45687);i(20388);let c={"zh-CN":e=>`\u{9884}\u{8BA1}\u{9605}\u{8BFB}\u{65F6}\u{95F4}: ${e.minutes>=1?`${Math.ceil(e.minutes)} \u{5206}\u{949F}`:"\u5C0F\u4E8E 1 \u5206\u949F"}`,"en-US":e=>`Estimated reading time: ${e.minutes>=1?`${Math.ceil(e.minutes)} minutes`:"less than 1 minute"}`};function r(e,n,i){let s=Object.keys(c).includes(n)?n:i;return c[s](e)}n.Z=e=>{let{defaultLocale:n="en-US"}=e,i=(0,l.Vi)().page.readingTimeData,c=(0,l.Jr)(),o=(0,l.e7)(),[a,d]=(0,t.useState)(r(i,c,n));return(0,t.useEffect)(()=>{d(r(i,c,n))},[c,i]),(0,s.jsx)("span",{"data-dark":String(o),className:"rp-reading-time",children:a})}}}]);