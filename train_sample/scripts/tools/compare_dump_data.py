import argparse
import enum
import os
import pickle
import re
from enum import unique
from typing import Any, Callable, Dict, List, Tuple

import numpy as np
import pandas as pd

from hat.core.cam_box3d import CameraInstance3DBoxes
from hat.core.data_struct.img_structures import ImgObjDet

EPS = np.finfo(np.float32).eps


class DataEncoder:
    @staticmethod
    def parse(base_data: Any, cmp_data: Any):

        assert type(base_data) == type(cmp_data)

        if isinstance(base_data, (int, float)):
            base_data = np.array([base_data])
            cmp_data = np.array([cmp_data])
        if isinstance(base_data, CameraInstance3DBoxes):
            base_data = base_data.tensor.detach().cpu().numpy()
            cmp_data = cmp_data.tensor.detach().cpu().numpy()
        if isinstance(base_data, ImgObjDet):
            base_data = base_data.img
            cmp_data = cmp_data.img
        if isinstance(base_data, np.ndarray):
            if base_data.size > 0:
                if isinstance(base_data.reshape(-1)[0], np.bool_):
                    base_data = base_data.astype(int)
                    cmp_data = cmp_data.astype(int)
                elif isinstance(base_data.reshape(-1)[0], str):
                    base_data = "".join(base_data)
                    cmp_data = "".join(cmp_data)

        return base_data, cmp_data


@unique
class RegExp(enum.Enum):
    BATCH_DATA = ".*batch_data"
    MODEL_OUTS = ".*model_outs"
    GRAD_BEFORE_OPTIMIZER = ".*grad_before_optimizer"
    PARAMS_BEFORE_OPTIMIZER = ".*param_before_optimizer"


def cmp_data_by_diff(base_data, cmp_data, key=""):
    assert isinstance(base_data, type(cmp_data)), (
        f"The type of base_data and cmp_data should be same, "
        f"but got {type(base_data)} vs {type(cmp_data)}"
    )
    if base_data is None and cmp_data is None:
        return {
            "key": key,
            "all_same": "True",
            "max_base_data": "None",
            "max_cmp_data": "None",
            "min_base_data": "None",
            "min_cmp_data": "None",
            "max_diff": "None",
            "diff_elem_num": "None",
            "diff_percent": "None",
            "check_result": "Pass",
        }

    base_data, cmp_data = DataEncoder.parse(base_data, cmp_data)

    if isinstance(base_data, str):
        all_same = base_data == cmp_data
        if all_same:
            diff_idx = len(base_data) - 1
            max_diff = 0
        else:
            diff_idx = 0
            for idx, s1, s2 in enumerate(zip(base_data, cmp_data)):
                if not (s1 == s2):
                    break
                diff_idx = idx

            max_diff = f"{base_data[diff_idx:]} VS {cmp_data[diff_idx:]}"

        diff_elem_num = len(base_data[diff_idx:]) + len(cmp_data[diff_idx:])
        diff_percent = diff_elem_num / (len(base_data) + len(cmp_data))
        max_base_data, max_cmp_data = base_data, cmp_data
        min_base_data, min_cmp_data = base_data, cmp_data
    else:  # np.ndarray
        try:
            all_same = np.alltrue(base_data == cmp_data)
            if all_same:
                diff_elem_num = 0
                max_diff, diff_percent = 0, 0
                max_base_data, max_cmp_data = np.max(base_data), np.max(
                    cmp_data
                )
                min_base_data, min_cmp_data = np.min(base_data), np.min(
                    cmp_data
                )
            else:
                diff = np.abs(base_data - cmp_data)
                all_same = np.all(diff <= EPS)
                diff_elem_num = (diff > EPS).sum()
                max_base_data, max_cmp_data = np.max(base_data), np.max(
                    cmp_data
                )
                min_base_data, min_cmp_data = np.min(base_data), np.min(
                    cmp_data
                )
                max_diff = np.max(diff)
                diff_percent = diff_elem_num / base_data.size
        except Exception as e:
            print("Compare data failed: ", str(e))
            return {
                "key": key,
                "all_same": "Failed",
                "max_base_data": "Failed",
                "max_cmp_data": "Failed",
                "min_base_data": "Failed",
                "min_cmp_data": "Failed",
                "max_diff": "Failed",
                "diff_elem_num": "Failed",
                "diff_percent": "Failed",
                "check_result": f"Failed: {str(e)}",
            }

    return {
        "key": key,
        "all_same": all_same,
        "max_base_data": max_base_data,
        "max_cmp_data": max_cmp_data,
        "min_base_data": min_base_data,
        "min_cmp_data": min_cmp_data,
        "max_diff": max_diff,
        "diff_elem_num": diff_elem_num,
        "diff_percent": str(round(diff_percent * 100, 2)) + "%",
        "check_result": "Pass" if all_same else "Failed",
    }


class DumpDataComparer(object):
    """Compare the differences between two dumped files \
        generated by `DumpData` callbacks.

    Args:
        base_file: File path of basic dump data.
        cmp_file: File path of dump data to compare.
        diff_func: Function used to compare differences.
        regexs: List of regular expressions used to filter comparison data.
        output_dir: Save Path.
    """

    def __init__(
        self,
        base_file: str,
        cmp_file: str,
        diff_func: Callable,
        output_dir: str,
        regexs: List[str],
    ):

        self.base_file = base_file
        self.cmp_file = cmp_file
        self.output_dir = output_dir

        self.diff_func = diff_func
        self.regex_list = regexs

    def diff_dump_data(self, file_name):
        base_data = self._read_pkl(self.base_file)
        cmp_data = self._read_pkl(self.cmp_file)

        all_ranks_base_data, all_ranks_cmp_data = {}, {}

        for rank_idx, (rank_base_data, rank_cmp_data) in enumerate(
            zip(base_data, cmp_data)
        ):

            (
                filter_rank_base_data,
                filter_rank_cmp_data,
            ) = self._filter_rank_data_by_regexs(
                rank_base_data, rank_cmp_data
            )  # noqa E501

            all_ranks_base_data[f"rank_{rank_idx}"] = filter_rank_base_data
            all_ranks_cmp_data[f"rank_{rank_idx}"] = filter_rank_cmp_data

        all_ranks_base_data, all_ranks_cmp_data = self._flat_dict(
            all_ranks_base_data
        ), self._flat_dict(all_ranks_cmp_data)

        df_data = []
        same_count = 0
        for k in sorted(list(all_ranks_base_data.keys())):  # noqa
            if k in all_ranks_cmp_data:
                v1 = all_ranks_base_data[k]
                v2 = all_ranks_cmp_data[k]
                diff = self.diff_func(v1, v2, k)
                df_data.append(diff)
                if diff["all_same"] not in ["Failed", False]:
                    same_count += 1
                else:
                    print(f"[DumpData Compare] Diff: {diff}")
        self.same_rate = same_count / len(df_data)
        df = pd.DataFrame(data=df_data, columns=list(df_data[0].keys()))

        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)

        save_file = os.path.join(self.output_dir, f"{file_name}.csv")
        df.to_csv(save_file, index=False)

    def _flat_dict(self, obj: Any, sep="."):
        def _flat(obj, prefix_key=None):
            if isinstance(obj, dict):
                for key, value in obj.items():
                    key = prefix_key + sep + key if prefix_key else key
                    yield from _flat(value, key)
            elif isinstance(obj, (List, Tuple)):
                for idx, data in enumerate(obj):
                    key = (
                        prefix_key + sep + str(idx) if prefix_key else str(idx)
                    )
                    yield from _flat(data, key)
            else:
                yield (prefix_key, obj)

        return {k: v for (k, v) in _flat(obj)}

    def _filter_rank_data_by_regexs(self, rank_base_data, rank_cmp_data):
        filter_rank_base_data = {}
        filter_rank_cmp_data = {}
        for (
            step_idx,
            step_base_data,
        ) in rank_base_data.items():
            assert step_idx in rank_cmp_data

            filter_step_base_data = {}
            filter_step_cmp_data = {}
            for regex in self.regex_list:
                regex_step_base_data = self._filter_data_by_regex(
                    step_base_data, regex=regex
                )
                regex_step_cmp_data = self._filter_data_by_regex(
                    rank_cmp_data[step_idx], regex=regex
                )

                filter_step_base_data.update(regex_step_base_data)
                filter_step_cmp_data.update(regex_step_cmp_data)

            filter_rank_base_data.update({step_idx: filter_step_base_data})
            filter_rank_cmp_data.update({step_idx: filter_step_cmp_data})

        return filter_rank_base_data, filter_rank_cmp_data

    def _filter_data_by_regex(self, data: Dict, regex) -> Dict:
        return dict(
            filter(
                lambda item: re.match(regex, item[0]) is not None,
                data.items(),
            )
        )

    def _read_pkl(self, file_path):
        with open(file_path, "rb") as f:
            data = pickle.load(f)
        return data


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--base-file",
        type=str,
        default="",
        required=True,
        help="path of stable base data",
    )
    parser.add_argument(
        "--cmp-file",
        type=str,
        default="",
        required=True,
        help="path of test data",
    )
    parser.add_argument(
        "--diff-inputs",
        action="store_true",
        default=False,
        help="diff batch data",
    )
    parser.add_argument(
        "--diff-outputs",
        action="store_true",
        default=False,
        help="diff model outs",
    )
    parser.add_argument(
        "--diff-grad",
        action="store_true",
        default=False,
        help="diff grad(before optimizer.step())",
    )
    parser.add_argument(
        "--diff-params",
        action="store_true",
        default=False,
        help="diff params(before optimizer.step())",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="./",
        required=False,
        help="path to save file",
    )
    parser.add_argument(
        "--file-name",
        type=str,
        default="diff_reports",
        required=False,
        help="path to save file",
    )
    args = parser.parse_args()
    return args


if __name__ == "__main__":
    args = parse_args()

    regex_list = []

    if args.diff_inputs:
        regex_list.append(RegExp.BATCH_DATA.value)

    if args.diff_outputs:
        regex_list.append(RegExp.MODEL_OUTS.value)

    if args.diff_grad:
        regex_list.append(RegExp.GRAD_BEFORE_OPTIMIZER.value)

    if args.diff_params:
        regex_list.append(RegExp.PARAMS_BEFORE_OPTIMIZER.value)

    comparer = DumpDataComparer(
        base_file=args.base_file,
        cmp_file=args.cmp_file,
        regexs=regex_list,
        output_dir=args.output_dir,
        diff_func=cmp_data_by_diff,
    )

    comparer.diff_dump_data(args.file_name)
    print(f"same rate: {comparer.same_rate}")
